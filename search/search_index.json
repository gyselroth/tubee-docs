{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"About tubee What ist tubee? tubee is a data management engine with proxy capabilities for other services and its core feature is the possibility to synchronize data between multiple services (endpoints) such as databases, ldap server, file formats, web applications and more. Everything can be fully automated using tubee. You may specify different synchronization workflows and defined custom attribute mappings. Create scripted attributes, conditions, synchronization jobs and more. tubee can be used to automatically synchronize your objecs between multiple endpoints. This can be everything in its nature, for example synchronize user accounts from an XML file to Active Directory and MongoDB. Do whatever you have to do. Licensing This software is freely available under the terms of GPL-3.0 including this documenation. Contribute There are many ways to contribute. Also just reporting issues and features requests will help to make the software better! Please continue reading in the Contributing chapter . Changelog A changelog is available here .","title":"About tubee"},{"location":"#about-tubee","text":"","title":"About tubee"},{"location":"#what-ist-tubee","text":"tubee is a data management engine with proxy capabilities for other services and its core feature is the possibility to synchronize data between multiple services (endpoints) such as databases, ldap server, file formats, web applications and more. Everything can be fully automated using tubee. You may specify different synchronization workflows and defined custom attribute mappings. Create scripted attributes, conditions, synchronization jobs and more. tubee can be used to automatically synchronize your objecs between multiple endpoints. This can be everything in its nature, for example synchronize user accounts from an XML file to Active Directory and MongoDB. Do whatever you have to do.","title":"What ist tubee?"},{"location":"#licensing","text":"This software is freely available under the terms of GPL-3.0 including this documenation.","title":"Licensing"},{"location":"#contribute","text":"There are many ways to contribute. Also just reporting issues and features requests will help to make the software better! Please continue reading in the Contributing chapter .","title":"Contribute"},{"location":"#changelog","text":"A changelog is available here .","title":"Changelog"},{"location":"overview/","text":"Overview First of all, tubee is just a simple data management application. Meaning you may enter data, edit it and remove it. tubee uses MongoDB as its main database. Therefore this application is highly scalable to your needs. Tubee itself is also written for fast performance and is easy scalable. Well this is not a big deal so far, pretty straight forward stuff. The real tubee features come into play when you need to sync your data resources to other systems such as databases, ldap server, structured data files such as XML, web services and more. tubee can handle various such services (they are called endpoints in tubee). You may import or export such services and create specific time triggered jobs for such tasks. It is also possible to use tubee as a proxy layer between users and such endpoints. Meaning you can have all tubee features for endpoints. Where tubee also glances is, you can query those very endpoints with the same query language. tubee acts as a central data manager and proxy layer between various services. tubee comes with a full featured REST API and provides OpenAPI schemas. Everything in tubee is a resource, a namespace, a collection, data itself and so on. Meaning you manipulate resources which are stored on the tubee server. tubee acts as a user-friendly data management engine. Unlike (most) native databases, tubee provides features like LDAP authentication, OpenID-connect integration, schema based collections of data obejcts, handles object relations, provides a nice HTTP API and much more. More features Namespace support Supports Import/Export to and from various different technologies Resource versioning Full asynchronous sync jobs Time triggered sync jobs RBAC Proxy for supported endpoints (Access endpoints via the tubee layer) Query rewriting for different endpoints (Query data from endpoints with the same query language) Attribute mapping between tubee and endpoints Attribtue scripting, rewriting and more Attribute map workflows Full featured OpenAPI v2 REST API SDK for 3rt party software Published as debian package, tar archive and docker image Full support for a cloud native deployment like on Kubernetes Perfectly scalable for your needs Console client for Linux, Windows and OSX Endpoints Endpoints LDAP (OpenLDAP, ActiveDirectory and other LDAP server) Various SQL Databases (PDO, All relational SQL database engines) Native MySQL/MariaDB MongoDB Moodle balloon ODataRest (Like Microsoft online (Office365 and more)) XML (via different storage backends, see Storage drivers) CSV (via different storage backends, see Storage drivers) JSON (via different storage backends, see Storage drivers) Binary Images (via different storage backends, see Storage drivers) Ucs (Univetion Corporate Server) Storage drivers for data formats: LocalFilesystem balloon cloud server SMB (Windows/Samba share via smb) Stream (HTTP,FTP and more) Resource types The tubee server works with various different resource types. Resource Description Namespace Resources like collections must be part of a single namespace. Collection A collection is group of similar data objects. Each collection holds data objects and is part of a namespace. Endpoint An endpoint represents a remote server for proxy, import from, or export to. DataObject An actual object which must be part of a collection. DataObjectRelation Represents a relationship between data objects. EndpointObject Besides data objects there are also endpoint objects. The diference is that an endpoint object represents the state of an object on an endpoint. Workflow A workflow defines how and what data should be synchronized between endpoints and collections. A workflow is always attached to an endpoint. GarbageWorkflow Similar to a Workflow but only applies to DataObjects which are not available from a source endpoint anymore. Secret Holds sensible data which can be injected into other resources. Usually secrets injected into endpoint resources. User A simple user with password authentication. (You may also use OpenID-connect or LDAP auth adapter instead local user resources) AccessRole Defines an access role which can be used to gain access. Authenticated users are are part of an access-rule. AccessRule Create access rules (RBAC) based on HTTP requests. Job A jobs defines what endpoints/collections should be synchronized and at what time/interval. Process A process represents a single execution of a job. Log Each process/job will create log resources which can be requested for Jobs, Processes, Collections, Endpoints and DataObjects. Resource overview A resource is always constructed the same, each resources contains attributes like name, version, created and changed timestamps, secret mounts, status, the type of the resource and _links. Usually those attributes are immutable once created. However most resources contain a data field where mutable data is stored. Some resources may offer a field status where the status of the resource gets represented. _links: self: href: - https://localhost:8090/api/v1/namespaces/foo/collections/accounts/endpoints/mssql namespace: href: 'https://localhost:8090/api/v1/namespaces/foo' collection: href: 'https://localhost:8090/api/v1/namespaces/foo/collections/accounts' id: 5bd1ab2e03541800194579b2 name: mssql version: 3 created: '2018-10-25T11:38:23+00:00' changed: '2018-11-16T14:00:46+00:00' secrets: - secret: foo key: bar to: data.resource.passwd kind: PdoEndpoint namespace: foo collection: accounts data: type: source options: flush: false import: - person_id filter_one: null filter_all: null resource: dsn: 'sqlsrv:server=tcp:dbserv.local,1433 ; Database = foo' username: tubee options: [] table: mytable status: available: true Resource naming The resource name is the identifier of each resource. The name has to be unique in its own resource context. For example there can be multiple endpoint resources called foo but they must not be attached to the same collection. A resource name is immutable. Meaning once a resource has been created, the name can not be changed. However it still possible to remove the resource and create it with another name. There are only certain characters allowed for a resource name: A-Z, a-z, 0-9 and . _ and -, everything else will get rejected by the server.","title":"Overview"},{"location":"overview/#overview","text":"First of all, tubee is just a simple data management application. Meaning you may enter data, edit it and remove it. tubee uses MongoDB as its main database. Therefore this application is highly scalable to your needs. Tubee itself is also written for fast performance and is easy scalable. Well this is not a big deal so far, pretty straight forward stuff. The real tubee features come into play when you need to sync your data resources to other systems such as databases, ldap server, structured data files such as XML, web services and more. tubee can handle various such services (they are called endpoints in tubee). You may import or export such services and create specific time triggered jobs for such tasks. It is also possible to use tubee as a proxy layer between users and such endpoints. Meaning you can have all tubee features for endpoints. Where tubee also glances is, you can query those very endpoints with the same query language. tubee acts as a central data manager and proxy layer between various services. tubee comes with a full featured REST API and provides OpenAPI schemas. Everything in tubee is a resource, a namespace, a collection, data itself and so on. Meaning you manipulate resources which are stored on the tubee server. tubee acts as a user-friendly data management engine. Unlike (most) native databases, tubee provides features like LDAP authentication, OpenID-connect integration, schema based collections of data obejcts, handles object relations, provides a nice HTTP API and much more.","title":"Overview"},{"location":"overview/#more-features","text":"Namespace support Supports Import/Export to and from various different technologies Resource versioning Full asynchronous sync jobs Time triggered sync jobs RBAC Proxy for supported endpoints (Access endpoints via the tubee layer) Query rewriting for different endpoints (Query data from endpoints with the same query language) Attribute mapping between tubee and endpoints Attribtue scripting, rewriting and more Attribute map workflows Full featured OpenAPI v2 REST API SDK for 3rt party software Published as debian package, tar archive and docker image Full support for a cloud native deployment like on Kubernetes Perfectly scalable for your needs Console client for Linux, Windows and OSX","title":"More features"},{"location":"overview/#endpoints","text":"Endpoints LDAP (OpenLDAP, ActiveDirectory and other LDAP server) Various SQL Databases (PDO, All relational SQL database engines) Native MySQL/MariaDB MongoDB Moodle balloon ODataRest (Like Microsoft online (Office365 and more)) XML (via different storage backends, see Storage drivers) CSV (via different storage backends, see Storage drivers) JSON (via different storage backends, see Storage drivers) Binary Images (via different storage backends, see Storage drivers) Ucs (Univetion Corporate Server) Storage drivers for data formats: LocalFilesystem balloon cloud server SMB (Windows/Samba share via smb) Stream (HTTP,FTP and more)","title":"Endpoints"},{"location":"overview/#resource-types","text":"The tubee server works with various different resource types. Resource Description Namespace Resources like collections must be part of a single namespace. Collection A collection is group of similar data objects. Each collection holds data objects and is part of a namespace. Endpoint An endpoint represents a remote server for proxy, import from, or export to. DataObject An actual object which must be part of a collection. DataObjectRelation Represents a relationship between data objects. EndpointObject Besides data objects there are also endpoint objects. The diference is that an endpoint object represents the state of an object on an endpoint. Workflow A workflow defines how and what data should be synchronized between endpoints and collections. A workflow is always attached to an endpoint. GarbageWorkflow Similar to a Workflow but only applies to DataObjects which are not available from a source endpoint anymore. Secret Holds sensible data which can be injected into other resources. Usually secrets injected into endpoint resources. User A simple user with password authentication. (You may also use OpenID-connect or LDAP auth adapter instead local user resources) AccessRole Defines an access role which can be used to gain access. Authenticated users are are part of an access-rule. AccessRule Create access rules (RBAC) based on HTTP requests. Job A jobs defines what endpoints/collections should be synchronized and at what time/interval. Process A process represents a single execution of a job. Log Each process/job will create log resources which can be requested for Jobs, Processes, Collections, Endpoints and DataObjects.","title":"Resource types"},{"location":"overview/#resource-overview","text":"A resource is always constructed the same, each resources contains attributes like name, version, created and changed timestamps, secret mounts, status, the type of the resource and _links. Usually those attributes are immutable once created. However most resources contain a data field where mutable data is stored. Some resources may offer a field status where the status of the resource gets represented. _links: self: href: - https://localhost:8090/api/v1/namespaces/foo/collections/accounts/endpoints/mssql namespace: href: 'https://localhost:8090/api/v1/namespaces/foo' collection: href: 'https://localhost:8090/api/v1/namespaces/foo/collections/accounts' id: 5bd1ab2e03541800194579b2 name: mssql version: 3 created: '2018-10-25T11:38:23+00:00' changed: '2018-11-16T14:00:46+00:00' secrets: - secret: foo key: bar to: data.resource.passwd kind: PdoEndpoint namespace: foo collection: accounts data: type: source options: flush: false import: - person_id filter_one: null filter_all: null resource: dsn: 'sqlsrv:server=tcp:dbserv.local,1433 ; Database = foo' username: tubee options: [] table: mytable status: available: true","title":"Resource overview"},{"location":"overview/#resource-naming","text":"The resource name is the identifier of each resource. The name has to be unique in its own resource context. For example there can be multiple endpoint resources called foo but they must not be attached to the same collection. A resource name is immutable. Meaning once a resource has been created, the name can not be changed. However it still possible to remove the resource and create it with another name. There are only certain characters allowed for a resource name: A-Z, a-z, 0-9 and . _ and -, everything else will get rejected by the server.","title":"Resource naming"},{"location":"quick-start/","text":"Quick start You need two things to get started, a server (usually you want a hosted server) and tubectl. tubectl is the tubee console client for Linux, Windows and OS X. Get tubectl All releases and executeable binaries are available tubee @github . Besides installing the binary manually, you may also install it from a package repository. Linux For debian based users you may just the tubee apt repository and install the latest client from there: apt-get -y install apt-transport-https echo deb https://dl.bintray.com/gyselroth/tubee stable main | sudo tee -a /etc/apt/sources.list wget -qO - https://bintray.com/user/downloadSubjectPublicKey?username=gyselroth | sudo apt-key add - sudo apt-get update apt-get install tubectl OSX As OSX user you may install tubectl using brew: brew tap gyselroth/core brew install tubectl tubectl first steps At first you have tell tubectl what tubee server you want to communicate to and you must provide your authentication credentials: tubectl login -u raffis -P -s https://tubee.example Note tubectl login stores your password in your operating systems credentials vault. You may be asked to unlock it. As of tubectl v1.0.0 it is only possible to authenticate using http basic credentials eventough the tubee server also offers OpenID-connect. By default self signed ssl certificated are not accepted by tubectl, however you may change this behaviour by setting the option -a or --allow-self-signed accordingly. Lets start our first request and query the available namespaces: tubectl get ns This lists all namespace resources in a pretty table. For requesting resources you need to use get , to edit resources edit and of course to create new ones create . You may just execute tubectl without any options to get the available commands: tubectl Usage: [options] [command] Options: -f, --config file Specify the config for the client (If different than ~/.tubee/config) -c, --context name Specify a tubee context (Using a different tubee environement) -d, --debug Print request in verbose mode) Commands: login Login resources get Get resources edit Edit resources explain Describe a resource delete Delete resources create Create resources sync Sync resources Note tubecl loads its config (.yml) from the users home directory (~/.tubee/config) and only holds configuration data like the tubee server. You may specify a custom configuration by specifying -c path/to/config . Help explain resources Using help explains you what certain commands do, like: tubectl help login A very useful command is also explain. Using explain describes entire resource types. For example you might want to know what PdoEndpoint is and what can be configured: tubectl explain PdoEndpoint Playground How does it all work and looks like? Want to play around with? You may want to import a playground with defines various resources and possibilities. This will create a namespace playground with example data. This may also be useful for new developers to test resources. tubectl apply -f https://raw.githubusercontent.com/gyselroth/tubee/dev/example/dump.yaml","title":"Quick start"},{"location":"quick-start/#quick-start","text":"You need two things to get started, a server (usually you want a hosted server) and tubectl. tubectl is the tubee console client for Linux, Windows and OS X.","title":"Quick start"},{"location":"quick-start/#get-tubectl","text":"All releases and executeable binaries are available tubee @github . Besides installing the binary manually, you may also install it from a package repository.","title":"Get tubectl"},{"location":"quick-start/#linux","text":"For debian based users you may just the tubee apt repository and install the latest client from there: apt-get -y install apt-transport-https echo deb https://dl.bintray.com/gyselroth/tubee stable main | sudo tee -a /etc/apt/sources.list wget -qO - https://bintray.com/user/downloadSubjectPublicKey?username=gyselroth | sudo apt-key add - sudo apt-get update apt-get install tubectl","title":"Linux"},{"location":"quick-start/#osx","text":"As OSX user you may install tubectl using brew: brew tap gyselroth/core brew install tubectl","title":"OSX"},{"location":"quick-start/#tubectl-first-steps","text":"At first you have tell tubectl what tubee server you want to communicate to and you must provide your authentication credentials: tubectl login -u raffis -P -s https://tubee.example Note tubectl login stores your password in your operating systems credentials vault. You may be asked to unlock it. As of tubectl v1.0.0 it is only possible to authenticate using http basic credentials eventough the tubee server also offers OpenID-connect. By default self signed ssl certificated are not accepted by tubectl, however you may change this behaviour by setting the option -a or --allow-self-signed accordingly. Lets start our first request and query the available namespaces: tubectl get ns This lists all namespace resources in a pretty table. For requesting resources you need to use get , to edit resources edit and of course to create new ones create . You may just execute tubectl without any options to get the available commands: tubectl Usage: [options] [command] Options: -f, --config file Specify the config for the client (If different than ~/.tubee/config) -c, --context name Specify a tubee context (Using a different tubee environement) -d, --debug Print request in verbose mode) Commands: login Login resources get Get resources edit Edit resources explain Describe a resource delete Delete resources create Create resources sync Sync resources Note tubecl loads its config (.yml) from the users home directory (~/.tubee/config) and only holds configuration data like the tubee server. You may specify a custom configuration by specifying -c path/to/config .","title":"tubectl first steps"},{"location":"quick-start/#help-explain-resources","text":"Using help explains you what certain commands do, like: tubectl help login A very useful command is also explain. Using explain describes entire resource types. For example you might want to know what PdoEndpoint is and what can be configured: tubectl explain PdoEndpoint","title":"Help &amp; explain resources"},{"location":"quick-start/#playground","text":"How does it all work and looks like? Want to play around with? You may want to import a playground with defines various resources and possibilities. This will create a namespace playground with example data. This may also be useful for new developers to test resources. tubectl apply -f https://raw.githubusercontent.com/gyselroth/tubee/dev/example/dump.yaml","title":"Playground"},{"location":"advanced/best-practics/","text":"Best practics Using secrets Secrets should be used to secure any sensitive information like access tokens, passwords or certificates. Naming conventions Collection plural Collection resources should be named in plural. For example accounts and not account since a collection usually holds multiple objects. Endpoints An endpoint should always be named the same in each collection. For example: There is a collection accounts with a destination endpoint openldap-mydomain . There is also a collection named groups which also exports data to the same OpenLDAP server. This endpoint should also be named openldap-mydomain . This is possibile since an endpoint name must only be unique for each namespace/collection pair. Workflow performance It is a good choice to put workflows first which are executed most likely first. Meaning setting the priority to 1 and if there are other worflows give them a lower priority. That way there is no need to execute multiple workflows to determine which one will match an applied.","title":"Best practics"},{"location":"advanced/best-practics/#best-practics","text":"","title":"Best practics"},{"location":"advanced/best-practics/#using-secrets","text":"Secrets should be used to secure any sensitive information like access tokens, passwords or certificates.","title":"Using secrets"},{"location":"advanced/best-practics/#naming-conventions","text":"","title":"Naming conventions"},{"location":"advanced/best-practics/#collection-plural","text":"Collection resources should be named in plural. For example accounts and not account since a collection usually holds multiple objects.","title":"Collection plural"},{"location":"advanced/best-practics/#endpoints","text":"An endpoint should always be named the same in each collection. For example: There is a collection accounts with a destination endpoint openldap-mydomain . There is also a collection named groups which also exports data to the same OpenLDAP server. This endpoint should also be named openldap-mydomain . This is possibile since an endpoint name must only be unique for each namespace/collection pair.","title":"Endpoints"},{"location":"advanced/best-practics/#workflow-performance","text":"It is a good choice to put workflows first which are executed most likely first. Meaning setting the priority to 1 and if there are other worflows give them a lower priority. That way there is no need to execute multiple workflows to determine which one will match an applied.","title":"Workflow performance"},{"location":"advanced/scripting/","text":"Scripting Tubee makes use of googles V8 javascript engine to provide the possible way to achieve dynamic attribute scripting or condition resolution. The basic knowlegde about scripting is, that it is imporant to provide a return value by using the function core.result() , this doc will provide some advanced knowlegde for scripts. Debug scripts Debugging scripts can be a pain but using the provided logger makes life easier. You may use core.logger.debug('foobar') to send debug information to the tubee core logger. Besides debug there are also (emergency,critical,error,warning,notice,info) available but usually debug is just fine since we only want to log during debugging sessions. For example the current processed object my be logged by calling: core.logger.debug(JSON.stringify(object)); Other inbuilt functionality Hashing Since there is no crypt in vanially javascript, crypt/hash functionality is provided by using core.crypt.hash('algorithm', 'value') . core.crypt.hash('sha1', core.object.data.password)) DataObject = EndpointObject We know already that we can access the current processing object by core.object . If the object is of kind DataObject there are some additions to mention: All object relations are available at core.object.relations Endpoint sync stats are available at core.object.endpoints The objects attributes are at core.object.data For example a more comlex script which loops all object relations and selects the relation with the biggest data.weight number. var primary=null; for(let relation of core.object.relations) { if(relation.object.collection === 'roles' (primary === null || relation.object.data.weight primary.data.weight)) {primary = relation.object;} }; core.result('uid='+core.object.data.username+',ou='+primary.data.name+',o=company,dc=example,dc=org') The other way around EndpointObject = DataObject, core.object only holds all fields from the EndpointObject directly.","title":"Scripting"},{"location":"advanced/scripting/#scripting","text":"Tubee makes use of googles V8 javascript engine to provide the possible way to achieve dynamic attribute scripting or condition resolution. The basic knowlegde about scripting is, that it is imporant to provide a return value by using the function core.result() , this doc will provide some advanced knowlegde for scripts.","title":"Scripting"},{"location":"advanced/scripting/#debug-scripts","text":"Debugging scripts can be a pain but using the provided logger makes life easier. You may use core.logger.debug('foobar') to send debug information to the tubee core logger. Besides debug there are also (emergency,critical,error,warning,notice,info) available but usually debug is just fine since we only want to log during debugging sessions. For example the current processed object my be logged by calling: core.logger.debug(JSON.stringify(object));","title":"Debug scripts"},{"location":"advanced/scripting/#other-inbuilt-functionality","text":"","title":"Other inbuilt functionality"},{"location":"advanced/scripting/#hashing","text":"Since there is no crypt in vanially javascript, crypt/hash functionality is provided by using core.crypt.hash('algorithm', 'value') . core.crypt.hash('sha1', core.object.data.password))","title":"Hashing"},{"location":"advanced/scripting/#dataobject-endpointobject","text":"We know already that we can access the current processing object by core.object . If the object is of kind DataObject there are some additions to mention: All object relations are available at core.object.relations Endpoint sync stats are available at core.object.endpoints The objects attributes are at core.object.data For example a more comlex script which loops all object relations and selects the relation with the biggest data.weight number. var primary=null; for(let relation of core.object.relations) { if(relation.object.collection === 'roles' (primary === null || relation.object.data.weight primary.data.weight)) {primary = relation.object;} }; core.result('uid='+core.object.data.username+',ou='+primary.data.name+',o=company,dc=example,dc=org') The other way around EndpointObject = DataObject, core.object only holds all fields from the EndpointObject directly.","title":"DataObject =&gt; EndpointObject"},{"location":"advanced/tubectl-config/","text":"tubectl config The tubectl config may be requested using tubectl get config . A typical config resource looks like this: context: - username: admin url: 'https://localhost:8090' allowSelfSigned: true name: dev defaultNamespace: test - username: raffis url: 'https://tubeestage' allowSelfSigned: false name: stage kind: Config defaultContext: stage Edit config The configuration may be modified using tubectl edit config . Note tubectl login will also modify the configuration in a more user friendly way. Context You may use different tubee environments easily with tubectl by using different contexts. Using tubectl login will create a new context named default . As long as you do not specify a different context using -c or --context accordingly the context default gets used. If you would like to specify a new context just set a different context during tubectl login : tubectl --context production login -s https://tubee-prod -u admin -p admin This will create a new context named production . You may specify the context for every request, for example: tubectl --context production get ps Default context The default context is usually named default . You may change the default context in the tubectl config: tubectl edit config and set defaultContext to another context name. Configuring context A context may have different settings, usually how tubectl can connect to a tubee server. Field Type Description username string The username using to authenticate. url string tubee server URL. allowSelfSigned boolean If true tubectl may accept self signed ssl certificates. name string The name of the tubectl context. defaultNamespace string Specify a different default namespace other than default . Note There is no way to configure a secret here. Secrets are stored in the operating systems credential vault and may only be changed/added using tubectl login .","title":"tubectl config"},{"location":"advanced/tubectl-config/#tubectl-config","text":"The tubectl config may be requested using tubectl get config . A typical config resource looks like this: context: - username: admin url: 'https://localhost:8090' allowSelfSigned: true name: dev defaultNamespace: test - username: raffis url: 'https://tubeestage' allowSelfSigned: false name: stage kind: Config defaultContext: stage","title":"tubectl config"},{"location":"advanced/tubectl-config/#edit-config","text":"The configuration may be modified using tubectl edit config . Note tubectl login will also modify the configuration in a more user friendly way.","title":"Edit config"},{"location":"advanced/tubectl-config/#context","text":"You may use different tubee environments easily with tubectl by using different contexts. Using tubectl login will create a new context named default . As long as you do not specify a different context using -c or --context accordingly the context default gets used. If you would like to specify a new context just set a different context during tubectl login : tubectl --context production login -s https://tubee-prod -u admin -p admin This will create a new context named production . You may specify the context for every request, for example: tubectl --context production get ps","title":"Context"},{"location":"advanced/tubectl-config/#default-context","text":"The default context is usually named default . You may change the default context in the tubectl config: tubectl edit config and set defaultContext to another context name.","title":"Default context"},{"location":"advanced/tubectl-config/#configuring-context","text":"A context may have different settings, usually how tubectl can connect to a tubee server. Field Type Description username string The username using to authenticate. url string tubee server URL. allowSelfSigned boolean If true tubectl may accept self signed ssl certificates. name string The name of the tubectl context. defaultNamespace string Specify a different default namespace other than default . Note There is no way to configure a secret here. Secrets are stored in the operating systems credential vault and may only be changed/added using tubectl login .","title":"Configuring context"},{"location":"operations/apply/","text":"Apply from file tubectl apply is an advanced command to create and modify one or multiple resources from a file. Existing resources get updated and new ones get created accordingly. For example a file resources.yaml with the following content is given: name: default kind: Namespace --- name: news namespace: default kind: Collection Executing tubectl apply -f resources.yaml will create those two resources for you. You may edit this file locally and run tubectl apply -f resources.yaml again to apply your changes. Note The order of resources does not matter. tubectl will order the resources for you automatically. name: default kind: Namespace --- name: news namespace: default kind: Collection data: schema: title: string Executing tubectl apply -f resources.yaml again will leave the namespace resource default untouched since nothing changed but will update the collection news .","title":"Apply from file"},{"location":"operations/apply/#apply-from-file","text":"tubectl apply is an advanced command to create and modify one or multiple resources from a file. Existing resources get updated and new ones get created accordingly. For example a file resources.yaml with the following content is given: name: default kind: Namespace --- name: news namespace: default kind: Collection Executing tubectl apply -f resources.yaml will create those two resources for you. You may edit this file locally and run tubectl apply -f resources.yaml again to apply your changes. Note The order of resources does not matter. tubectl will order the resources for you automatically. name: default kind: Namespace --- name: news namespace: default kind: Collection data: schema: title: string Executing tubectl apply -f resources.yaml again will leave the namespace resource default untouched since nothing changed but will update the collection news .","title":"Apply from file"},{"location":"operations/create/","text":"Create resources A new resource can easily be created using tubectl create resource . By default tubectl tries to open your editor of choice. The editor gets selected from the env variable EDITOR . tubectl create ns You may as well specify the editor: EDITOR=vi tubectl create ns After exiting the editor, tubectl tries to create the specified resource, if this fails for whatever reason the error message gets prepended on the top and you may correct the error. If you do not change anything and quit a second time the editor gets closed. Your changes are not lost, tubectl creates a temporary file in your temp directory which still exists after you quit. This may just get reapplied using the -f or --file option. Could not create resource /tmp/.vaaFmRP.yml Apply this resource again: tubectl create -f /tmp/.vaaFmRP.yml Set resource name before open editor It is certainly possible to already name the resource before open it. Just specify the name after the resource type (or at last argument after the other required arguments if some resource types require more). This will still open the resource and you may continue configuring it. EDITOR=vi tubectl create ns foobar Specify input format The create operation opens the editor and you may create your resource. By default yaml is expected, this may be changed by setting the option -i or --input accordingly. tubectl create ns -i json Read from file By default tubectl opens a temporary file where you create the new resource. You may tell tubectl where to read an existing file from and skip the editor. tubectl create -f resources.yaml Note The more advanced command tubectl apply will also update resources if they may already exist. Read from stdin You may as well read from stdin instead creating a file manually. This is done by specifying -s or --stdin accordingly. For example you may clone a resource like this: tubectl get ns foo -o yaml | tubectl create -s Open from stdin will always open the content in your editor since cloning can never be done automatically since at least the resource name must get changed. Create from template There is a possibility to open a template in the editor. Meaning you have pre defined fields so you actually know what you can configure. This is done by specifying --from--template . tubectl create ep mycollection -n mynamespace --from-template This will open the requested resource with all configuration possibilities. Usually you only need to modify things in data , and the resource coordinates such as namespace , collection , endpoint and name . namespace: mynamespace collection: mycollection _links: self: href: null # string undefined name: null # string Resource identifier. Note that the name is immutable once created on the server and must be unique in its own resource context. id: null # string Unique 12-byte resource identifier. Note this is a MongoDB ObjectId. The name is the standard resource identifier, the id only useful to verify that a given resource was completely recreated. An ID is immutable and will be created on the server. version: null # number The version of the resource. A version gets increased once the resource have been modified. created: null # string ISO 8601 timestamp when the resource was created. changed: null # string ISO 8601 timestamp when the resource was changed. secrets: null # array Injected secrets in this resource. kind: null # string [PdoEndpoint,MysqlEndpoint,XmlEndpoint,CsvEndpoint,ImageEndpoint,JsonEndpoint,MongodbEndpoint,MoodleEndpoint,BalloonEndpoint,OdataRestEndpoint,UcsEndpoint] The type of endpoint. data: type: browse # string [browse,source,destination,bidirectional] Specify the type of the endpoint. options: identifier: null # string Endpoint resource identifier. import: null # array A list of attributes which gets used to uniquely identify an object on the endpoint. flush: false # boolean If true and the endpoint is of type source, the endpoint gets flushed before export. If the type is destination, the endpoints collection gets flushed before import. Pay attention with flush as it may result in data loss! filter_one: null # string Specify an endpoint filter which gets used to filter for a single object. filter_all: null # string Specify a filter which always gets applied to the endpoint if objects are retrieved. You may as well set a specifc resource type as argument to --from-template . This may be required if you want to create a new endpoint: tubectl create ep mycollection -n mynamespace --from-template MongodbEndpoint","title":"Create resources"},{"location":"operations/create/#create-resources","text":"A new resource can easily be created using tubectl create resource . By default tubectl tries to open your editor of choice. The editor gets selected from the env variable EDITOR . tubectl create ns You may as well specify the editor: EDITOR=vi tubectl create ns After exiting the editor, tubectl tries to create the specified resource, if this fails for whatever reason the error message gets prepended on the top and you may correct the error. If you do not change anything and quit a second time the editor gets closed. Your changes are not lost, tubectl creates a temporary file in your temp directory which still exists after you quit. This may just get reapplied using the -f or --file option. Could not create resource /tmp/.vaaFmRP.yml Apply this resource again: tubectl create -f /tmp/.vaaFmRP.yml","title":"Create resources"},{"location":"operations/create/#set-resource-name-before-open-editor","text":"It is certainly possible to already name the resource before open it. Just specify the name after the resource type (or at last argument after the other required arguments if some resource types require more). This will still open the resource and you may continue configuring it. EDITOR=vi tubectl create ns foobar","title":"Set resource name before open editor"},{"location":"operations/create/#specify-input-format","text":"The create operation opens the editor and you may create your resource. By default yaml is expected, this may be changed by setting the option -i or --input accordingly. tubectl create ns -i json","title":"Specify input format"},{"location":"operations/create/#read-from-file","text":"By default tubectl opens a temporary file where you create the new resource. You may tell tubectl where to read an existing file from and skip the editor. tubectl create -f resources.yaml Note The more advanced command tubectl apply will also update resources if they may already exist.","title":"Read from file"},{"location":"operations/create/#read-from-stdin","text":"You may as well read from stdin instead creating a file manually. This is done by specifying -s or --stdin accordingly. For example you may clone a resource like this: tubectl get ns foo -o yaml | tubectl create -s Open from stdin will always open the content in your editor since cloning can never be done automatically since at least the resource name must get changed.","title":"Read from stdin"},{"location":"operations/create/#create-from-template","text":"There is a possibility to open a template in the editor. Meaning you have pre defined fields so you actually know what you can configure. This is done by specifying --from--template . tubectl create ep mycollection -n mynamespace --from-template This will open the requested resource with all configuration possibilities. Usually you only need to modify things in data , and the resource coordinates such as namespace , collection , endpoint and name . namespace: mynamespace collection: mycollection _links: self: href: null # string undefined name: null # string Resource identifier. Note that the name is immutable once created on the server and must be unique in its own resource context. id: null # string Unique 12-byte resource identifier. Note this is a MongoDB ObjectId. The name is the standard resource identifier, the id only useful to verify that a given resource was completely recreated. An ID is immutable and will be created on the server. version: null # number The version of the resource. A version gets increased once the resource have been modified. created: null # string ISO 8601 timestamp when the resource was created. changed: null # string ISO 8601 timestamp when the resource was changed. secrets: null # array Injected secrets in this resource. kind: null # string [PdoEndpoint,MysqlEndpoint,XmlEndpoint,CsvEndpoint,ImageEndpoint,JsonEndpoint,MongodbEndpoint,MoodleEndpoint,BalloonEndpoint,OdataRestEndpoint,UcsEndpoint] The type of endpoint. data: type: browse # string [browse,source,destination,bidirectional] Specify the type of the endpoint. options: identifier: null # string Endpoint resource identifier. import: null # array A list of attributes which gets used to uniquely identify an object on the endpoint. flush: false # boolean If true and the endpoint is of type source, the endpoint gets flushed before export. If the type is destination, the endpoints collection gets flushed before import. Pay attention with flush as it may result in data loss! filter_one: null # string Specify an endpoint filter which gets used to filter for a single object. filter_all: null # string Specify a filter which always gets applied to the endpoint if objects are retrieved. You may as well set a specifc resource type as argument to --from-template . This may be required if you want to create a new endpoint: tubectl create ep mycollection -n mynamespace --from-template MongodbEndpoint","title":"Create from template"},{"location":"operations/delete/","text":"Delete resources Using tubectl delete will completely remove resources. You may recreate resourced with the same name, they will only differ by their resource id. This will remove the workflow create from the endpoint csv within the accounts collection. tubectl delete wf accounts csv create -n playground Note Be very careful by deleting resources of type DataObject. They will loose their entire state and can not get removed from any possible export endpoints. It is best practics to define a deleted timestamp field instead.","title":"Delete resources"},{"location":"operations/delete/#delete-resources","text":"Using tubectl delete will completely remove resources. You may recreate resourced with the same name, they will only differ by their resource id. This will remove the workflow create from the endpoint csv within the accounts collection. tubectl delete wf accounts csv create -n playground Note Be very careful by deleting resources of type DataObject. They will loose their entire state and can not get removed from any possible export endpoints. It is best practics to define a deleted timestamp field instead.","title":"Delete resources"},{"location":"operations/edit/","text":"Modify resources Modify resources is a combination of options between get and create operations. You may query for resources to get changed and edit them in your editor of choice. tubectl edit co mycollection -n mynamespace The editing works the same as it does for create . Query and edit It is possible to use most options which are also known to working for get. So for example it is possible to query resources and edit them directly: tubectl edit do mycollection -q data.field1=test,data.field2=foo -n mynamespace This will query for DataObject resources whereas data.field1 is test and data.field2 is foo. A List object is mutable as well as long as you edit the resource within the list. A resource of type List itself is immutable.","title":"Modify resources"},{"location":"operations/edit/#modify-resources","text":"Modify resources is a combination of options between get and create operations. You may query for resources to get changed and edit them in your editor of choice. tubectl edit co mycollection -n mynamespace The editing works the same as it does for create .","title":"Modify resources"},{"location":"operations/edit/#query-and-edit","text":"It is possible to use most options which are also known to working for get. So for example it is possible to query resources and edit them directly: tubectl edit do mycollection -q data.field1=test,data.field2=foo -n mynamespace This will query for DataObject resources whereas data.field1 is test and data.field2 is foo. A List object is mutable as well as long as you edit the resource within the list. A resource of type List itself is immutable.","title":"Query and edit"},{"location":"operations/get/","text":"Request Query resources tubectl get knows various different options to request the resources you actually want. First you need to specify the type of resource you want to query ( tubectl get resource [name] ). This will list the latest 20 resources of the requested type in a pretty table. By default the tubee server orders its resource by the created date/time of the resource. tubectl get ns +---------------------------+---------------------------+---------------------------+---------------------------+ | Name | Version | Changed | Created | |---------------------------|---------------------------|---------------------------|---------------------------| | foo | 1 | 3 weeks ago | 4 weeks ago | +---------------------------+---------------------------+---------------------------+---------------------------+ | bar | 3 | 2 weeks ago | 4 weeks ago | +---------------------------+---------------------------+---------------------------+---------------------------+ If only the resource type is specified, a resource type List gets returned by the server which holds the desired resource types. It is certainly possible to specify by name what resource should get returned. tubeectl get ns foo Most resource types know an alias to help you to type as fast as possible. ns in this case is the same as namespaces . tubectl help get lists all possible resources to query from and also their related alias. Note Not all resource types have an alias. Usually only resource with a name 6 characters. Sort output You may change the default sorting behaviour of the server if you specify -s or --sort accordingly. tubectl get ns --sort name This will query the latest namespaces sorted by the resource name. You may change the sort order by specifying asc or desc. tubectl get ns --sort name=desc You may as well specify multiple fileds comma separated. tubectl get ns --sort name=desc,changed=asc If the human styled way to sort output does not fit your needs it is still possible to request a custom sort specification using json. You may specify this with --json-sort . This gets interpreted by the server as such and must be a valid MongoDB sort definition. This will do the same job as above: tubectl get ns --json-sort '{ name :0, changed :1}' Change the output format By default tubectl will try to pretty print the requested resources in a table on your shell. By design this output may not hold the information you require. The output format can be changed by using -o or --output accordingly. Besides the default there is also yaml or json output. Note Some resources such as Log may also have even more possibilities. tubectl get ns -o yaml which results in a yaml style output: kind: List _links: self: href: 'https://localhost:8090/api/v1/namespaces?offset=0 limit=20' count: 1 total: 1 data: - _links: self: href: - https://localhost:8090/api/v1/namespaces?query=%7B%7D offset=NaN limit=20 sort=%7B%7D kind: Namespace id: 5bd1a94b035418001a337722 name: foo version: 1 created: '2018-10-25T11:30:19+00:00' changed: '2018-10-25T11:30:19+00:00' secrets: [] You may also draw a custom table by using cc and specify comma separated label:value. The follwing example will print all endpoints within the playground namespace and list the name and the endpoint type. tubectl get ep playground foo -o cc= Name:name,Endpoint Type:data.type +---------------------------+---------------------------+ | Name | Endpoint Type | |---------------------------|---------------------------| | foo | destination | |---------------------------|---------------------------| | bar | destination | |---------------------------|---------------------------| | foobar | source | +---------------------------+---------------------------+ Query search resources Usually the latest 20 resources are not enaugh to work with. By using the option -q or --field-selector you may find the needed resource. Like the sort operation a query works in the format key=value and may be delimited by , . Keep in mind that delimiting will work as AND queries. However it is possible to specify -q or --field-selector multiple times which will result in OR queries. Note There may be endpoints which do not accept such complex queries (Like the Ucs endpoint). tubectl get ns -q name=bar Note To find a resource by name just specify the name after the resource type since this is the shorthand method to the above example. or a more complex example: tubectl get ns -q name=bar,version=1 -q name=foo Like --json-sort there is also a possibility to use --json-query . Likewise sort the query definition is a MongoDB style query . tubectl get ns --json-query '{ $or :[ changed :{ $gt : 2018-10-25 },{ name : bar }]}' Using resources in other namespaces The default namespace is default . You may request a different namespace by using -n or --namespace accordingly. For example to query all collections in the namespace foo: tubectl get co -n foo You may configure a different default namespace by using tubectl edit config . Tail resources By default tubecli lists the latest 20 resources ordered by created date/time. Meaning the first record is the newest one and the last the oldest (If not more than 20 resources of the requested type are available). By using -t or --tail accordingly the output is reversed. Meaning the last record is the newest and the first the oldest (Again, if there are not more than 20 resources available of that type.) Resource history diff Each modification on a resource will result in an incrision of the resource version and the old version gets stored safely. You can find the resource version in the default output on most resource types or by specifying a custom output such as yaml. The resources history can be requested if -v or --history accordingly is specified. Note that if this option is requested a resource name must be specified. You can not request the history on a List response (Multiple resources). -H will list all older versions of the requested resource. tubectl get ns foo -H tubectl features also diff mechanism whereas you might find differences between resource version much more easily. By specifying -d or --diff accordingly one can compare the resource differences in the difftool of your choice. Note You need to set an env variable DIFFTOOL on your host system for that case or start tubectl with such. On linux, vimdiff is highly recommended. This will compare the namespace foo (current version) with the version 1 of itself. DIFFTOOL=vimdiff tubectl get ns foo --diff 1 Limit resources in lists By default you get the newest 20 resources. You may lower this limit by using -L or --limit accordingly or increase to a maximum of 100 resources. tubectl get ns --limit 2 Note The limit can not be higher than 100. If more resources are required either specify a more exact query or request a stream by using --stream . Stream To retrive a large list of resources you may use --stream which streams the resources back from the server instead normal request. tubectl get do foo --stream Watch realtime updates The tubee server can push realtime updates to listening clients. By specifying -w or --watch accordingly you will receive any updates made to resources of the requested list. This includes new resources, modifications or removals. Note that a watch request does operate for 5min and then dies. Watch does not include existing resources. If existing resource shall get returned, one may combine --stream and --watch .","title":"Request & Query resources"},{"location":"operations/get/#request-query-resources","text":"tubectl get knows various different options to request the resources you actually want. First you need to specify the type of resource you want to query ( tubectl get resource [name] ). This will list the latest 20 resources of the requested type in a pretty table. By default the tubee server orders its resource by the created date/time of the resource. tubectl get ns +---------------------------+---------------------------+---------------------------+---------------------------+ | Name | Version | Changed | Created | |---------------------------|---------------------------|---------------------------|---------------------------| | foo | 1 | 3 weeks ago | 4 weeks ago | +---------------------------+---------------------------+---------------------------+---------------------------+ | bar | 3 | 2 weeks ago | 4 weeks ago | +---------------------------+---------------------------+---------------------------+---------------------------+ If only the resource type is specified, a resource type List gets returned by the server which holds the desired resource types. It is certainly possible to specify by name what resource should get returned. tubeectl get ns foo Most resource types know an alias to help you to type as fast as possible. ns in this case is the same as namespaces . tubectl help get lists all possible resources to query from and also their related alias. Note Not all resource types have an alias. Usually only resource with a name 6 characters.","title":"Request &amp; Query resources"},{"location":"operations/get/#sort-output","text":"You may change the default sorting behaviour of the server if you specify -s or --sort accordingly. tubectl get ns --sort name This will query the latest namespaces sorted by the resource name. You may change the sort order by specifying asc or desc. tubectl get ns --sort name=desc You may as well specify multiple fileds comma separated. tubectl get ns --sort name=desc,changed=asc If the human styled way to sort output does not fit your needs it is still possible to request a custom sort specification using json. You may specify this with --json-sort . This gets interpreted by the server as such and must be a valid MongoDB sort definition. This will do the same job as above: tubectl get ns --json-sort '{ name :0, changed :1}'","title":"Sort output"},{"location":"operations/get/#change-the-output-format","text":"By default tubectl will try to pretty print the requested resources in a table on your shell. By design this output may not hold the information you require. The output format can be changed by using -o or --output accordingly. Besides the default there is also yaml or json output. Note Some resources such as Log may also have even more possibilities. tubectl get ns -o yaml which results in a yaml style output: kind: List _links: self: href: 'https://localhost:8090/api/v1/namespaces?offset=0 limit=20' count: 1 total: 1 data: - _links: self: href: - https://localhost:8090/api/v1/namespaces?query=%7B%7D offset=NaN limit=20 sort=%7B%7D kind: Namespace id: 5bd1a94b035418001a337722 name: foo version: 1 created: '2018-10-25T11:30:19+00:00' changed: '2018-10-25T11:30:19+00:00' secrets: [] You may also draw a custom table by using cc and specify comma separated label:value. The follwing example will print all endpoints within the playground namespace and list the name and the endpoint type. tubectl get ep playground foo -o cc= Name:name,Endpoint Type:data.type +---------------------------+---------------------------+ | Name | Endpoint Type | |---------------------------|---------------------------| | foo | destination | |---------------------------|---------------------------| | bar | destination | |---------------------------|---------------------------| | foobar | source | +---------------------------+---------------------------+","title":"Change the output format"},{"location":"operations/get/#query-search-resources","text":"Usually the latest 20 resources are not enaugh to work with. By using the option -q or --field-selector you may find the needed resource. Like the sort operation a query works in the format key=value and may be delimited by , . Keep in mind that delimiting will work as AND queries. However it is possible to specify -q or --field-selector multiple times which will result in OR queries. Note There may be endpoints which do not accept such complex queries (Like the Ucs endpoint). tubectl get ns -q name=bar Note To find a resource by name just specify the name after the resource type since this is the shorthand method to the above example. or a more complex example: tubectl get ns -q name=bar,version=1 -q name=foo Like --json-sort there is also a possibility to use --json-query . Likewise sort the query definition is a MongoDB style query . tubectl get ns --json-query '{ $or :[ changed :{ $gt : 2018-10-25 },{ name : bar }]}'","title":"Query &amp; search resources"},{"location":"operations/get/#using-resources-in-other-namespaces","text":"The default namespace is default . You may request a different namespace by using -n or --namespace accordingly. For example to query all collections in the namespace foo: tubectl get co -n foo You may configure a different default namespace by using tubectl edit config .","title":"Using resources in other namespaces"},{"location":"operations/get/#tail-resources","text":"By default tubecli lists the latest 20 resources ordered by created date/time. Meaning the first record is the newest one and the last the oldest (If not more than 20 resources of the requested type are available). By using -t or --tail accordingly the output is reversed. Meaning the last record is the newest and the first the oldest (Again, if there are not more than 20 resources available of that type.)","title":"Tail resources"},{"location":"operations/get/#resource-history-diff","text":"Each modification on a resource will result in an incrision of the resource version and the old version gets stored safely. You can find the resource version in the default output on most resource types or by specifying a custom output such as yaml. The resources history can be requested if -v or --history accordingly is specified. Note that if this option is requested a resource name must be specified. You can not request the history on a List response (Multiple resources). -H will list all older versions of the requested resource. tubectl get ns foo -H tubectl features also diff mechanism whereas you might find differences between resource version much more easily. By specifying -d or --diff accordingly one can compare the resource differences in the difftool of your choice. Note You need to set an env variable DIFFTOOL on your host system for that case or start tubectl with such. On linux, vimdiff is highly recommended. This will compare the namespace foo (current version) with the version 1 of itself. DIFFTOOL=vimdiff tubectl get ns foo --diff 1","title":"Resource history &amp; diff"},{"location":"operations/get/#limit-resources-in-lists","text":"By default you get the newest 20 resources. You may lower this limit by using -L or --limit accordingly or increase to a maximum of 100 resources. tubectl get ns --limit 2 Note The limit can not be higher than 100. If more resources are required either specify a more exact query or request a stream by using --stream .","title":"Limit resources in lists"},{"location":"operations/get/#stream","text":"To retrive a large list of resources you may use --stream which streams the resources back from the server instead normal request. tubectl get do foo --stream","title":"Stream"},{"location":"operations/get/#watch-realtime-updates","text":"The tubee server can push realtime updates to listening clients. By specifying -w or --watch accordingly you will receive any updates made to resources of the requested list. This includes new resources, modifications or removals. Note that a watch request does operate for 5min and then dies. Watch does not include existing resources. If existing resource shall get returned, one may combine --stream and --watch .","title":"Watch realtime updates"},{"location":"resources/collections/","text":"Collections Each DataObject needs to be placed in a collection. See collection as a pod of multiple and similar objects. A collection may define a schema for its DataObjects but this is optional. At its simplest form a collection just has a name. Create a new collection kind: Collection namespace: playground name: accounts tubectl create -f spec.yaml Check the just created resource: tubectl get co accounts -n playground -o yaml The collection accounts is now ready to be used. Define a collection with a schema A schema enforces DataObjects to be consistent with the provided schema. An attribute in a defined schema may specify the value type, a label and regex. Note Regex are of the type PCRE - Perl Compatible Regular Expressions. kind: Collection namespace: playground name: accounts data: schema: username: label: Username type: string require_regex: '#[a-zA-Z0-1]+#' firstname: label: Firstname type: string lastname: label: Surname type: string disabled: label: Surname type: int mail: label: Mail adress type: string require_regex: '#[a-zA-z0-9.-]+\\@[a-zA-z0-9.-]+.[a-zA-Z]+#' Note Changing a schema will have no affect on any existing DataObjects! DataObjects are only validated against the schema if they get added or modified. Attribute types tubee acknowledges the following valid attribute value types: Name Description string Just a simple string int A number positive or negative bool Boolean value, true or false float A comma number like 0.12 array Holds multiple values null Represents NULL values binary Binary content","title":"Collections"},{"location":"resources/collections/#collections","text":"Each DataObject needs to be placed in a collection. See collection as a pod of multiple and similar objects. A collection may define a schema for its DataObjects but this is optional. At its simplest form a collection just has a name.","title":"Collections"},{"location":"resources/collections/#create-a-new-collection","text":"kind: Collection namespace: playground name: accounts tubectl create -f spec.yaml Check the just created resource: tubectl get co accounts -n playground -o yaml The collection accounts is now ready to be used.","title":"Create a new collection"},{"location":"resources/collections/#define-a-collection-with-a-schema","text":"A schema enforces DataObjects to be consistent with the provided schema. An attribute in a defined schema may specify the value type, a label and regex. Note Regex are of the type PCRE - Perl Compatible Regular Expressions. kind: Collection namespace: playground name: accounts data: schema: username: label: Username type: string require_regex: '#[a-zA-Z0-1]+#' firstname: label: Firstname type: string lastname: label: Surname type: string disabled: label: Surname type: int mail: label: Mail adress type: string require_regex: '#[a-zA-z0-9.-]+\\@[a-zA-z0-9.-]+.[a-zA-Z]+#' Note Changing a schema will have no affect on any existing DataObjects! DataObjects are only validated against the schema if they get added or modified.","title":"Define a collection with a schema"},{"location":"resources/collections/#attribute-types","text":"tubee acknowledges the following valid attribute value types: Name Description string Just a simple string int A number positive or negative bool Boolean value, true or false float A comma number like 0.12 array Holds multiple values null Represents NULL values binary Binary content","title":"Attribute types"},{"location":"resources/data-objects/","text":"DataObjects A DataObject is a record from a Collection. It can represent anyting and may hold data of any kind (As long as it follows the collection schema). Create a new data object kind: DataObject namespace: playground collection: accounts name: user data: username: user mail: user@example.org firstname: user lastname: bar disabled: null tubectl create -f spec.yaml Check the just created resource: tubectl get do accounts user -n playground -o yaml","title":"DataObjects"},{"location":"resources/data-objects/#dataobjects","text":"A DataObject is a record from a Collection. It can represent anyting and may hold data of any kind (As long as it follows the collection schema).","title":"DataObjects"},{"location":"resources/data-objects/#create-a-new-data-object","text":"kind: DataObject namespace: playground collection: accounts name: user data: username: user mail: user@example.org firstname: user lastname: bar disabled: null tubectl create -f spec.yaml Check the just created resource: tubectl get do accounts user -n playground -o yaml","title":"Create a new data object"},{"location":"resources/data-relation-objects/","text":"DataRelationObjects DataRelationObjects represent a relationship between two (or more) DataObjects. This is similar to a cross table in traditional relation SQL database engines. One defines a relationship between two objects. All related objects can be retrieved from a single DataObject. A tubee DataObjectRelation holds the releated objects (This may also be cross namespace and/or cross collection) and optionally may hold unstructured context data which may provide more context data. Note tubee v1.0.0 only allows a relationship between exactly two DataObjects. (This behaviour will most likely be upgraded to allow an undefined number of cross relations). Create a new data object Lets say we have a group group1 in a collection groups and a user user1 in a collection users and we want to declare a relationship between those very objects: kind: DataObjectRelation namespace: playground name: user1-group2 data: relation: - namespace: playground collection: accounts object: user1 - namespace: playground collection: groups object: group1 context: foo: bar Note The namespace playground only defines in what namespace the relation object is placed, but not from what namespace the data objects are! tubectl create -f spec.yaml Check the just created resource: tubectl get re user1-group2 -n playground -o yaml DataObjectRelations can be automatically created during importing source endpoints and declaring map in attributes . Get relations tubectl get re will return a list of (all) unresolved DataRelationObjects. It is also possibile to retrive all related objects for a single DataObject directly using -r or --relations accordingly: tubectl get do accounts user1 --relations Given the example above, this will give us a list with relations for user1 : kind: List _links: self: href: - https://localhost:8090/api/v1/namespaces/playground/collections/accounts/objects/user1/relations?offset=0 limit=100 count: 1 total: 1 data: - _links: self: href: - https://localhost:8090/api/v1/namespaces/playground/collections/accounts/objects/user1/relations?query=%7B%7D offset=0 limit=100 sort=%7B%7D stream=false watch=false id: 5c519fd9d9a7d2009b7f0695 name: user1-group1 version: 1 created: '2019-01-30T13:00:09+00:00' changed: '2019-02-04T10:09:14+00:00' secrets: [] kind: DataObjectRelation namespace: playground data: context: foo: bar relation: - namespace: playground collection: accounts object: user1 - namespace: playground collection: groups object: group1 status: object: _links: self: href: - https://localhost:8090/api/v1/namespaces/playground/collections/accounts/objects/user1/relations?query=%7B%7D offset=0 limit=100 sort=%7B%7D stream=false watch=false namespace: href: - https://localhost:8090/api/v1/namespaces/playground?query=%7B%7D offset=0 limit=100 sort=%7B%7D stream=false watch=false collection: href: - https://localhost:8090/api/v1/namespaces/playground/collections/groups?query=%7B%7D offset=0 limit=100 sort=%7B%7D stream=false watch=false id: 5c3736e58ad7e303ed591e49 name: group1 version: 1 created: '2019-01-10T12:13:25+00:00' changed: '2019-01-10T12:13:25+00:00' secrets: [] kind: DataObject namespace: playground collection: groups data: name: group1 disabled: null","title":"DataRelationObjects"},{"location":"resources/data-relation-objects/#datarelationobjects","text":"DataRelationObjects represent a relationship between two (or more) DataObjects. This is similar to a cross table in traditional relation SQL database engines. One defines a relationship between two objects. All related objects can be retrieved from a single DataObject. A tubee DataObjectRelation holds the releated objects (This may also be cross namespace and/or cross collection) and optionally may hold unstructured context data which may provide more context data. Note tubee v1.0.0 only allows a relationship between exactly two DataObjects. (This behaviour will most likely be upgraded to allow an undefined number of cross relations).","title":"DataRelationObjects"},{"location":"resources/data-relation-objects/#create-a-new-data-object","text":"Lets say we have a group group1 in a collection groups and a user user1 in a collection users and we want to declare a relationship between those very objects: kind: DataObjectRelation namespace: playground name: user1-group2 data: relation: - namespace: playground collection: accounts object: user1 - namespace: playground collection: groups object: group1 context: foo: bar Note The namespace playground only defines in what namespace the relation object is placed, but not from what namespace the data objects are! tubectl create -f spec.yaml Check the just created resource: tubectl get re user1-group2 -n playground -o yaml DataObjectRelations can be automatically created during importing source endpoints and declaring map in attributes .","title":"Create a new data object"},{"location":"resources/data-relation-objects/#get-relations","text":"tubectl get re will return a list of (all) unresolved DataRelationObjects. It is also possibile to retrive all related objects for a single DataObject directly using -r or --relations accordingly: tubectl get do accounts user1 --relations Given the example above, this will give us a list with relations for user1 : kind: List _links: self: href: - https://localhost:8090/api/v1/namespaces/playground/collections/accounts/objects/user1/relations?offset=0 limit=100 count: 1 total: 1 data: - _links: self: href: - https://localhost:8090/api/v1/namespaces/playground/collections/accounts/objects/user1/relations?query=%7B%7D offset=0 limit=100 sort=%7B%7D stream=false watch=false id: 5c519fd9d9a7d2009b7f0695 name: user1-group1 version: 1 created: '2019-01-30T13:00:09+00:00' changed: '2019-02-04T10:09:14+00:00' secrets: [] kind: DataObjectRelation namespace: playground data: context: foo: bar relation: - namespace: playground collection: accounts object: user1 - namespace: playground collection: groups object: group1 status: object: _links: self: href: - https://localhost:8090/api/v1/namespaces/playground/collections/accounts/objects/user1/relations?query=%7B%7D offset=0 limit=100 sort=%7B%7D stream=false watch=false namespace: href: - https://localhost:8090/api/v1/namespaces/playground?query=%7B%7D offset=0 limit=100 sort=%7B%7D stream=false watch=false collection: href: - https://localhost:8090/api/v1/namespaces/playground/collections/groups?query=%7B%7D offset=0 limit=100 sort=%7B%7D stream=false watch=false id: 5c3736e58ad7e303ed591e49 name: group1 version: 1 created: '2019-01-10T12:13:25+00:00' changed: '2019-01-10T12:13:25+00:00' secrets: [] kind: DataObject namespace: playground collection: groups data: name: group1 disabled: null","title":"Get relations"},{"location":"resources/endpoints/","text":"Endpoints Endpoints are other services around tubee. An endpoint may represent an Active Directory, OpenLDAP server, MongoDB server, XMl file or much more. An endpoint is required if dataobjects needs to be exported or imported. An endpoint is always attached directly to a collection. If you have two or more collections and you want to synchronize objects from each of those, you will need to create an endpoint for each of those (And for every type of endpoint). You may also create an endpoint to just browse objects in it and do not use it for any synchronization which is actually the default. Create endpoint This will create an export endpoint and creates a JSON in /tmp/accounts.json with all data objects in the collection accounts. Note A workflow is required as well which defines the mapping between tubee and the JSON file. Using only an endpoint with no workflows does not do any action. name: json-export kind: JsonEndpoint namespace: playground collection: accounts data: storage: kind: StreamStorage type: destination options: identifier: null flush: true import: [] filter_one: null filter_all: null resource: [] file: /tmp/accounts.json tubectl create -f spec.yaml Check the just created resource: tubectl get ep accounts json-export -n playground -o yaml Destination endpoints Destination endpoints are used to export objects from tubee to another service. An endpoint with type destination always requires the option filter_one to be defined. This filter defines how an object on the endpoint can be uniquely identified by tubee. Like all tubee queries/filters this is a MongoDB DSL query. Like filter_one you may specify a filter_all which filters all data objects on the endpoint. This may be useful if the endpoint is of type source . Source endpoints Source endpoints are used to import objects from other services into tubee. Each record from the endpoint gets created as a single DataObject in a tubee collection. Source endpoints require the option import to be defined. This options holds a list of one or more attribute names which gets used to uniquely identify a tubee DataObject and its object on the endpoint. Endpoints Resource Description LdapEndpoint LDAP compatible server (OpenLDAP, Active Directory, ...) PdoEndpoint SQL server MysqlEndpoint MySQL/MariaDB server (native client) MongodbEndpoint MongoDB server MoodleEndpoint Moodle BalloonEndpoint balloon cloud server ODataRestEndpoint REST API defined as OData , like microsoft online services (graph API, Office 365). XmlEndpoint Xml data format CsvEndpoint Csv data format JsonEndpoint Json data format ImageEndpoint Binary images UcsEndpoint Univention Corporate server XmlEndpoint, CsvEndpoint, JsonEndpoint and ImageEndpoint use a storage technolgy to define where data can be read or written. Possible storage drivers are: Name Description LocalFilesystem Path on the local filesystem where the tubee server runs Balloon balloon cloud server Smb Windows/Samba share Stream Stream (HTTP, FTP, ...)","title":"Endpoints"},{"location":"resources/endpoints/#endpoints","text":"Endpoints are other services around tubee. An endpoint may represent an Active Directory, OpenLDAP server, MongoDB server, XMl file or much more. An endpoint is required if dataobjects needs to be exported or imported. An endpoint is always attached directly to a collection. If you have two or more collections and you want to synchronize objects from each of those, you will need to create an endpoint for each of those (And for every type of endpoint). You may also create an endpoint to just browse objects in it and do not use it for any synchronization which is actually the default.","title":"Endpoints"},{"location":"resources/endpoints/#create-endpoint","text":"This will create an export endpoint and creates a JSON in /tmp/accounts.json with all data objects in the collection accounts. Note A workflow is required as well which defines the mapping between tubee and the JSON file. Using only an endpoint with no workflows does not do any action. name: json-export kind: JsonEndpoint namespace: playground collection: accounts data: storage: kind: StreamStorage type: destination options: identifier: null flush: true import: [] filter_one: null filter_all: null resource: [] file: /tmp/accounts.json tubectl create -f spec.yaml Check the just created resource: tubectl get ep accounts json-export -n playground -o yaml","title":"Create endpoint"},{"location":"resources/endpoints/#destination-endpoints","text":"Destination endpoints are used to export objects from tubee to another service. An endpoint with type destination always requires the option filter_one to be defined. This filter defines how an object on the endpoint can be uniquely identified by tubee. Like all tubee queries/filters this is a MongoDB DSL query. Like filter_one you may specify a filter_all which filters all data objects on the endpoint. This may be useful if the endpoint is of type source .","title":"Destination endpoints"},{"location":"resources/endpoints/#source-endpoints","text":"Source endpoints are used to import objects from other services into tubee. Each record from the endpoint gets created as a single DataObject in a tubee collection. Source endpoints require the option import to be defined. This options holds a list of one or more attribute names which gets used to uniquely identify a tubee DataObject and its object on the endpoint.","title":"Source endpoints"},{"location":"resources/endpoints/#endpoints_1","text":"Resource Description LdapEndpoint LDAP compatible server (OpenLDAP, Active Directory, ...) PdoEndpoint SQL server MysqlEndpoint MySQL/MariaDB server (native client) MongodbEndpoint MongoDB server MoodleEndpoint Moodle BalloonEndpoint balloon cloud server ODataRestEndpoint REST API defined as OData , like microsoft online services (graph API, Office 365). XmlEndpoint Xml data format CsvEndpoint Csv data format JsonEndpoint Json data format ImageEndpoint Binary images UcsEndpoint Univention Corporate server XmlEndpoint, CsvEndpoint, JsonEndpoint and ImageEndpoint use a storage technolgy to define where data can be read or written. Possible storage drivers are: Name Description LocalFilesystem Path on the local filesystem where the tubee server runs Balloon balloon cloud server Smb Windows/Samba share Stream Stream (HTTP, FTP, ...)","title":"Endpoints"},{"location":"resources/jobs/","text":"Jobs Jobs are required to create a synchronization deployment. Unlinke Processes they are a persistent resource and work as a template for processes. Each job will trigger processes. A process defines when, how often and what endpoints get synchronized. Jobs trigger processes which are managed by the tubee task scheduler which is based on \\TaskScheduler` . Jobs define what endpoints trigger parallel processes and in what order, they also define intervaly, retry levels and timeouts. Create job name: hourly kind: Job namespace: kzu data: notification: enabled: false receiver: [] collections: - [ accounts , courses , groups ] endpoints: - mssql-import - mssql-relations - [ ldap-export , balloon-export ] simulate: false log_level: debug ignore: true options: at: 0 interval: 3600 retry: 0 retry_interval: 0 timeout: 0 tubectl create -f spec.yaml Check the just created resource: tubectl get jobs hourly -n playground -o yaml Parallelism It is important to understand how jobs trigger processes and how they work in parallel using the maximum amount of resources (Nodes and cpu cores). Synchron processes To create a simple process order whereas endpoint named a should be processed first and as soon as it finishes it will trigger a second process for endpoint b , both for the collection named accounts . data: collections: - accounts endpoints: - a - b This job configuration will trigger a total of three processes: The main process The sync process for the endpoint a The sync process for the endpoint b Note The main process is always finished as soon as all child processes were executed. Parallel processes To create parallel processes, one may specify a list of endpoints and/or collections: data: collections: - ['accounts', 'groups'] endpoints: - a - b This will trigger a total of 5 processes: The main process One process for accounts.a and one for groups.a at the same time One process for accounts.b and one for groups.b Simulation A job can be entirely simulated by specify data.simulate to true . The default is false . While simulation is enabled, everything gets executed as usual but actions only get simulated. There will be no changes, neither on tubee nor on any endpoints. Logging By default jobs get executed within a log level error . This log level may be changed to one of: emergency critical error warning notice info debug Be very careful with low levels like debug . Low log levels have a massive impact on the performance and should only be used during initial testing and conifguration. Continue on error Normally a process terminates as soon as it encounters an exception. By setting data.ignore to true the processor will ignore such errors and continues with the next object. The default is false but it is usually safe and a good idea to set it to true . Notification A job might trigger mail notification as soon as it has been executed. Notification is disabled by default but may be enabled by setting data.notification.enabled to true . A notification may be sent to multiple receiver but at least one needs to be specified: data: notification: enabled: true receiver: - admin@example.org Job timing By default a jobs triggers only once and never again. Usually this not what is wanted. One may specify an interval time to let a job retrigger. It is also possible to set a specific time when the job should trigger the first time. This setup will lead to an immediate trigger as soon as the job gets created and will retrigger every hour. data: options: at: 0 interval 3600 The option data.options.at is by default 0 which means immedieately but it may be changed to a unix timestamp. It will trigger a process at the time given. Retry Errors If a job fails (or one of its processes), it may trigger a retry process. By default this mechanism is disabled but might be enabled by specifying a retry number data.options.retry . 2 would mean the process should get triggered up to two times if it fails. If a retry gets configured, it is best practics to define an interval, otherwise the time slot between failures might be too low that any issue was resolved in the meantime. This example will trigger up to two times with an interval of 30min (three inclunding the first try): data: options: retry: 2 retry_interval: 1800 If data.options.ignore is true there are still some circumstandes whereas a process might fail, for example if an endpoint can not get initialized due network errors. Timeouts It is possible to configure a timeout data.options.timeout which is by default 0 (No timeout). Be careful with timeouts as they leave endpoints in incomplete conditions.","title":"Jobs"},{"location":"resources/jobs/#jobs","text":"Jobs are required to create a synchronization deployment. Unlinke Processes they are a persistent resource and work as a template for processes. Each job will trigger processes. A process defines when, how often and what endpoints get synchronized. Jobs trigger processes which are managed by the tubee task scheduler which is based on \\TaskScheduler` . Jobs define what endpoints trigger parallel processes and in what order, they also define intervaly, retry levels and timeouts.","title":"Jobs"},{"location":"resources/jobs/#create-job","text":"name: hourly kind: Job namespace: kzu data: notification: enabled: false receiver: [] collections: - [ accounts , courses , groups ] endpoints: - mssql-import - mssql-relations - [ ldap-export , balloon-export ] simulate: false log_level: debug ignore: true options: at: 0 interval: 3600 retry: 0 retry_interval: 0 timeout: 0 tubectl create -f spec.yaml Check the just created resource: tubectl get jobs hourly -n playground -o yaml","title":"Create job"},{"location":"resources/jobs/#parallelism","text":"It is important to understand how jobs trigger processes and how they work in parallel using the maximum amount of resources (Nodes and cpu cores).","title":"Parallelism"},{"location":"resources/jobs/#synchron-processes","text":"To create a simple process order whereas endpoint named a should be processed first and as soon as it finishes it will trigger a second process for endpoint b , both for the collection named accounts . data: collections: - accounts endpoints: - a - b This job configuration will trigger a total of three processes: The main process The sync process for the endpoint a The sync process for the endpoint b Note The main process is always finished as soon as all child processes were executed.","title":"Synchron processes"},{"location":"resources/jobs/#parallel-processes","text":"To create parallel processes, one may specify a list of endpoints and/or collections: data: collections: - ['accounts', 'groups'] endpoints: - a - b This will trigger a total of 5 processes: The main process One process for accounts.a and one for groups.a at the same time One process for accounts.b and one for groups.b","title":"Parallel processes"},{"location":"resources/jobs/#simulation","text":"A job can be entirely simulated by specify data.simulate to true . The default is false . While simulation is enabled, everything gets executed as usual but actions only get simulated. There will be no changes, neither on tubee nor on any endpoints.","title":"Simulation"},{"location":"resources/jobs/#logging","text":"By default jobs get executed within a log level error . This log level may be changed to one of: emergency critical error warning notice info debug Be very careful with low levels like debug . Low log levels have a massive impact on the performance and should only be used during initial testing and conifguration.","title":"Logging"},{"location":"resources/jobs/#continue-on-error","text":"Normally a process terminates as soon as it encounters an exception. By setting data.ignore to true the processor will ignore such errors and continues with the next object. The default is false but it is usually safe and a good idea to set it to true .","title":"Continue on error"},{"location":"resources/jobs/#notification","text":"A job might trigger mail notification as soon as it has been executed. Notification is disabled by default but may be enabled by setting data.notification.enabled to true . A notification may be sent to multiple receiver but at least one needs to be specified: data: notification: enabled: true receiver: - admin@example.org","title":"Notification"},{"location":"resources/jobs/#job-timing","text":"By default a jobs triggers only once and never again. Usually this not what is wanted. One may specify an interval time to let a job retrigger. It is also possible to set a specific time when the job should trigger the first time. This setup will lead to an immediate trigger as soon as the job gets created and will retrigger every hour. data: options: at: 0 interval 3600 The option data.options.at is by default 0 which means immedieately but it may be changed to a unix timestamp. It will trigger a process at the time given.","title":"Job timing"},{"location":"resources/jobs/#retry-errors","text":"If a job fails (or one of its processes), it may trigger a retry process. By default this mechanism is disabled but might be enabled by specifying a retry number data.options.retry . 2 would mean the process should get triggered up to two times if it fails. If a retry gets configured, it is best practics to define an interval, otherwise the time slot between failures might be too low that any issue was resolved in the meantime. This example will trigger up to two times with an interval of 30min (three inclunding the first try): data: options: retry: 2 retry_interval: 1800 If data.options.ignore is true there are still some circumstandes whereas a process might fail, for example if an endpoint can not get initialized due network errors.","title":"Retry &amp; Errors"},{"location":"resources/jobs/#timeouts","text":"It is possible to configure a timeout data.options.timeout which is by default 0 (No timeout). Be careful with timeouts as they leave endpoints in incomplete conditions.","title":"Timeouts"},{"location":"resources/namespaces/","text":"Namespaces tubee has most things sorted in namespaces. Meaning a resource is attached on a namespace to avoid name conflicts and also make it easy to deploy RBAC rules. Create a new namespace kind: Namespace name: playground tubectl create -f spec.yaml Check the just created resource: tubectl get ns foobar -o yaml The namespace foobar is now ready. Note Namespace is the simplest resource type of all, it only requires a name.","title":"Namespaces"},{"location":"resources/namespaces/#namespaces","text":"tubee has most things sorted in namespaces. Meaning a resource is attached on a namespace to avoid name conflicts and also make it easy to deploy RBAC rules.","title":"Namespaces"},{"location":"resources/namespaces/#create-a-new-namespace","text":"kind: Namespace name: playground tubectl create -f spec.yaml Check the just created resource: tubectl get ns foobar -o yaml The namespace foobar is now ready. Note Namespace is the simplest resource type of all, it only requires a name.","title":"Create a new namespace"},{"location":"resources/secrets/","text":"Secrets Secrets contain sensitive information and may get injected into other resources. A secret may hold anything but is usually a password, digital certificate or access tokens. Secret resources get special treatment on the server. Their contents get encryted on the server and decrypted on request. Besides encryption, a secret is useful to not accidentally leak secret information while sharing resource definitions. Create Secret A secret holds its data in data and can be any key:value combination. The secret value must be encoded using base64. This is due a secret may also contain binary data. echo -n foobar200 | base64 echo -n cn=admin,dc=example,dc=org | base64 Note Using echo n is required otherwise echo will append a new line \\n and invalidates the secret. name: ldap-credentials kind: Secret namespace: playground data: binddn: Y249YWRtaW4sZGM9ZXhhbXBsZSxkYz1vcmc= bindpw: Zm9vYmFyMjAw tubectl create -f spec.yaml Check the just created resource: tubectl get secrets ldap-credentials -n playground -o yaml Inject secret A secret may be injected into any other resource using the field secrets . In this example lets inject the secret to an ldap endpoint: name: tam-ldap kind: LdapEndpoint namespace: playground collection: accounts data: type: destination resource: uri: ldap://openldap-endpoint basedn: ou=users,dc=example,dc=org options: filter_one: '{uid={map.uid}}' filter_all: '(objectClass=PosixAccount)' secrets: - secret: ldap-credentials key: binddn to: 'data.resource.binddn' - secret: ldap-credentials key: bindpw to: 'data.resource.bindpw' Injection options: Key Description secret The name of the secret to mount. key Specify the name of the key/value pair from the secret. to The place where the secrets value should get injected. . may be used to delimit a path. Note If the same path already exists in the resource definition itself, it will be overruled by the secret value.","title":"Secrets"},{"location":"resources/secrets/#secrets","text":"Secrets contain sensitive information and may get injected into other resources. A secret may hold anything but is usually a password, digital certificate or access tokens. Secret resources get special treatment on the server. Their contents get encryted on the server and decrypted on request. Besides encryption, a secret is useful to not accidentally leak secret information while sharing resource definitions.","title":"Secrets"},{"location":"resources/secrets/#create-secret","text":"A secret holds its data in data and can be any key:value combination. The secret value must be encoded using base64. This is due a secret may also contain binary data. echo -n foobar200 | base64 echo -n cn=admin,dc=example,dc=org | base64 Note Using echo n is required otherwise echo will append a new line \\n and invalidates the secret. name: ldap-credentials kind: Secret namespace: playground data: binddn: Y249YWRtaW4sZGM9ZXhhbXBsZSxkYz1vcmc= bindpw: Zm9vYmFyMjAw tubectl create -f spec.yaml Check the just created resource: tubectl get secrets ldap-credentials -n playground -o yaml","title":"Create Secret"},{"location":"resources/secrets/#inject-secret","text":"A secret may be injected into any other resource using the field secrets . In this example lets inject the secret to an ldap endpoint: name: tam-ldap kind: LdapEndpoint namespace: playground collection: accounts data: type: destination resource: uri: ldap://openldap-endpoint basedn: ou=users,dc=example,dc=org options: filter_one: '{uid={map.uid}}' filter_all: '(objectClass=PosixAccount)' secrets: - secret: ldap-credentials key: binddn to: 'data.resource.binddn' - secret: ldap-credentials key: bindpw to: 'data.resource.bindpw'","title":"Inject secret"},{"location":"resources/secrets/#injection-options","text":"Key Description secret The name of the secret to mount. key Specify the name of the key/value pair from the secret. to The place where the secrets value should get injected. . may be used to delimit a path. Note If the same path already exists in the resource definition itself, it will be overruled by the secret value.","title":"Injection options:"},{"location":"resources/workflows/","text":"Workflows A workflow defines how attributes are mapped between tubee and an endpoint. Workflows are required for both a source and a destination endpoint. For source endpoints a worklfow specifies what attributes from an endpoint are mapped to a tubee DataObject. The same is true for destination endpoint workflows but just reversed. Such a workflow defines what tubee attributes get mapped to a destination endpoint. Each endpoint may have more than one workflow however only one workflow can get selected and executed. What workflow is selected depends on what ensure type is set or if a condition allows the worklfow to get executed. Create workflow This will create a workflow for the endpoint named ldap within the collection accounts . name: create-update kind: Workflow namespace: playground collection: accounts endpoint: ldap data: priority: 0 ensure: last condition: core.result(core.object.data.disabled === false core.object.data.username) map: - name: entrydn kind: script value: core.result('uid='+core.object.data.username+',ou='+core.object.department+',o=company,dc=example,dc=org') required: true - name: uid kind: map value: data.username required: false - name: sn kind: map value: data.last_name required: false - name: givenName kind: map value: data.givenname required: false - name: cn kind: script value: core.result(core.object.data.firstname +' '+core.object.data.last_name) required: false - name: objectClass kind: static value: - inetOrgPerson required: true tubectl create -f spec.yaml Check the just created resource: tubectl get wf accounts ldap create-update -n playground -o yaml Ensure The ensure type defines what the workflow actually should do. It defines in what state a DataObject or an EndpointObject should be. There are three known ensure types: Ensure Description exists The resource gets created if it does not already exists. last The resource gets created if it does not already exists and if it does the resource gets updated. absent The resource gets removed. The default ensure type for a workflow is always last . Condition Each workflow may have a scripted condition. This condition gets execute and determines if a given workflow shall get executed. The condition is JavaScript and gets executed by googles V8 engine. The condition has to execute core.result( bool ) to define if the workflow should get executed. Each object traverses the workflow stack and gets tested against each workflow as soon as one workflow matches. Each currently processed object is available at core.object . Example: core.result(core.object.data.disabled === false core.object.data.username) This workflow only gets executed if the object has a property disabled with a value false and has a field username set. Note By default there is no condition. A workflow may only match if the ensure type does match. Priority Besides a condition and the ensure type there is possibility to set a priority in which order the workflows get tested. By default each workflow has the priority 0 . 0 is the highest priority. A workflow with the priority 0 gets executed before a worklfow with the priority 2 . Mapping The mapping is the most important fact about a workflow. The mapping defines what and how certain attributes get mapped to each other. For example it defines what attributes from a DataObject get mapped to what attributes of an OpenLDAP object. The mapping is defined within map and contains a list of attribute mappings. Each attribute mapping may have different options. Option Default Description name required The name of the destination attribute. (May also contain . to specify a deep path like data.username ). kind map May either be map (1:1 attribute mapping), static (static inline value) or script (scripted attribute using vanilla javascript (V8). ensure last Like a workflow itself, each attribute may have a different ensure level. value null Defines the value of the attribute. The value depends on what kind of attribute this is. type same type as value Convert the value to another type. rewrite [] Rewrite a mapped attribute to another value (May also be done using a scripted attribute). filter [] Chain of predefined string filters to apply unwind null Unwind a list and operate attribute options on each list element. skip false If true the attribute gets ignored. This may be useful if an attribute is only used for an object relation creation or relation context. map Define an object relation mapping to another collection. Automatically create DataObjectReations. writeonly false Writeonly flag may be set to true for attributes which get not returned by endpoints (writeonly attributes). Name The name is required and defines the name of the destination attribute name. Note Important, DataObject attributes are usually in the data container. For example, lets define an attribute from an active directory source endpoint and map the samAccountName to our DataObject. map: - name: data.username from: samAccountName The data. prefix is required since a DataObjects data is placed within a data container. See an example of a DataObject here . Kind There are three different attribute kinds while map is the default one. Kind Description map The value will hold the name of the source attribute from which value will be taken. The value must be string in this case since all attribute names are strings. static The value is a static value. It may be any supported type. script The value is a javascript executed by the V8 engine. The result must set by calling core.result() while the current DataObject is accessible using core.object . Ensure The ensure type on a attributes knows one more type merge compared to workflow itself. Ensure Description exists The attribute gets only mapped if it does not exists yet. last The attribute gets mapped with the latest value. absent The attribute gets removed. merge The attributes get merged, only useful if the value is an array/list. Defines mighty scipted attributes. The engine executes JavaScript and used the result of core.result() as the value for the attribute. Type By default the source attributes type will be untouched. However you may convert the value to another type. The same attribute types as defined in a collection schema are available. Note The type conversion takes place at the very end of the attribute mapping. Rewrite You may use rewrite rules to rewrite a value. Rewrite rules may either be of static matching using from or a regex ( PCRE ) matching using match . The rewrite processor stops as soon as either from or a regex match match the given attributes value. Example: map: - name: entrydn kind: script value: core.result('uid='+core.object.data.username+',ou='+core.object.department+',o=company,dc=example,dc=org') rewrite: - from: uid=admin,ou=admins,o=company,dc=example,dc=org to: uid=Administrator,ou=admins,o=company,dc=example,dc=org - match: #uid=([^,]),ou=hr,o=company,dc=example,dc=org# to: uid=$2,ou=secretariat,o=company,dc=example,dc=org - match: #uid=([^,]),ou=assistence,o=company,dc=example,dc=org# to: uid=$2,ou=secretariat,o=company,dc=example,dc=org Note Rewrite rules get execute once the value is determined from either from,value or script but before a possible type conversion. You may achive the same using scripted attributes. But rewrite rules are a more readable way and should be the preferred choice if you need to rewrite any values. Unwind Using unwind you may operate on each element within a list attribute. You may apply each attribute mapping option to a unwind operator. For example, we have a DataObject with an attribute adresses which is a list of adresses and we want to map all streets to an attribute called street. DataObject: kind: DataObject collection: people data: firstName: John lastName: Meyer adresses: - street: First street 20 zip: 33445 city: New York - street: Company street 38 zip: 3445 city: Zurich The goal is to get an attribute called street with the value ['First street 20', 'Company street 38'] . Lets unwind the attribute adresses and grab the value with from . Note While unwindig the each list value gets available at root . map: - name: street value: data.adresses unwind: from: root.street The same is achievable using scripted attributes, but like rewrite rules, unwinding may be the preferrable solution. ### Map Map is particulary useful to automatically create DataObjectRelations between DataObjects. DataObjectRelations represent a relationship between two (or more) DataObjects. Those DataObject may be from different collections and/or namespaces. Lets asume we have a collection named accounts and one named groups . We would like to import LDAP objects into both of them. Into accounts we import person objects and into group group objects. While importing we'd like to automatically create tubee DataObjectRelations between group and group members. Lets asume those LDAP group objects have an attribute member which is a list of user distinguished names. To automatically create a relationship we need to specify the map keyword and pointing the destination collection to accounts and the key which gets used to identify the destination account object to data.dn (data.dn will hold the account dn). Optionally we set an attribute ou as context. Example: map: - name: data.member value: member map: collection: accounts to: data.dn context: - ou skip: true - name: data.ou from: ou skip: true This mapping will automatically try to create DataObjectRelations between those two collections. Option Default Description collection required The name of the destination collection. to required The name of the DataObject in the destination collection to use as relationship reference. (Usually you will ned to specify the attribute within data. (for example data.id)). ensure last By default the relationship gets created and updated. You may set ensure to exists or absent while on exists the relation will not get updated (for example if context data gets changed). If absent the relation gets removed. context empty list A list of attributes to use as context attributes. (Note that you can also use attributes which have skip: true set.) Skip Skip is by default false. An attribute which has skip on true is declared as a virtual attribute and never gets written anywhere. However a skip: true attribute may be useful if it gets used to write a DataObjectRelation context (See Map ). Writeonly A password attribute is an example for such attributes. Passwords usually may be writeable but get not returned. While writeonly is set to true and DataObject already exists on the endpoint, the attribute does not get written. writeonly: true attributes may only get written during object creation. Note that it does not matter what value ensure holds while the attribute is set on writeonly and the DataObject already exists. Filter Specify an optional chain of filters to apply as string filters: Alnum Alpha BaseName Digits Dir HtmlEntities RealPath StringPrefix StringSuffix StringToLower StringToUpper StringTrim StripNewlines StripTags UriNormalize","title":"Workflows"},{"location":"resources/workflows/#workflows","text":"A workflow defines how attributes are mapped between tubee and an endpoint. Workflows are required for both a source and a destination endpoint. For source endpoints a worklfow specifies what attributes from an endpoint are mapped to a tubee DataObject. The same is true for destination endpoint workflows but just reversed. Such a workflow defines what tubee attributes get mapped to a destination endpoint. Each endpoint may have more than one workflow however only one workflow can get selected and executed. What workflow is selected depends on what ensure type is set or if a condition allows the worklfow to get executed.","title":"Workflows"},{"location":"resources/workflows/#create-workflow","text":"This will create a workflow for the endpoint named ldap within the collection accounts . name: create-update kind: Workflow namespace: playground collection: accounts endpoint: ldap data: priority: 0 ensure: last condition: core.result(core.object.data.disabled === false core.object.data.username) map: - name: entrydn kind: script value: core.result('uid='+core.object.data.username+',ou='+core.object.department+',o=company,dc=example,dc=org') required: true - name: uid kind: map value: data.username required: false - name: sn kind: map value: data.last_name required: false - name: givenName kind: map value: data.givenname required: false - name: cn kind: script value: core.result(core.object.data.firstname +' '+core.object.data.last_name) required: false - name: objectClass kind: static value: - inetOrgPerson required: true tubectl create -f spec.yaml Check the just created resource: tubectl get wf accounts ldap create-update -n playground -o yaml","title":"Create workflow"},{"location":"resources/workflows/#ensure","text":"The ensure type defines what the workflow actually should do. It defines in what state a DataObject or an EndpointObject should be. There are three known ensure types: Ensure Description exists The resource gets created if it does not already exists. last The resource gets created if it does not already exists and if it does the resource gets updated. absent The resource gets removed. The default ensure type for a workflow is always last .","title":"Ensure"},{"location":"resources/workflows/#condition","text":"Each workflow may have a scripted condition. This condition gets execute and determines if a given workflow shall get executed. The condition is JavaScript and gets executed by googles V8 engine. The condition has to execute core.result( bool ) to define if the workflow should get executed. Each object traverses the workflow stack and gets tested against each workflow as soon as one workflow matches. Each currently processed object is available at core.object . Example: core.result(core.object.data.disabled === false core.object.data.username) This workflow only gets executed if the object has a property disabled with a value false and has a field username set. Note By default there is no condition. A workflow may only match if the ensure type does match.","title":"Condition"},{"location":"resources/workflows/#priority","text":"Besides a condition and the ensure type there is possibility to set a priority in which order the workflows get tested. By default each workflow has the priority 0 . 0 is the highest priority. A workflow with the priority 0 gets executed before a worklfow with the priority 2 .","title":"Priority"},{"location":"resources/workflows/#mapping","text":"The mapping is the most important fact about a workflow. The mapping defines what and how certain attributes get mapped to each other. For example it defines what attributes from a DataObject get mapped to what attributes of an OpenLDAP object. The mapping is defined within map and contains a list of attribute mappings. Each attribute mapping may have different options. Option Default Description name required The name of the destination attribute. (May also contain . to specify a deep path like data.username ). kind map May either be map (1:1 attribute mapping), static (static inline value) or script (scripted attribute using vanilla javascript (V8). ensure last Like a workflow itself, each attribute may have a different ensure level. value null Defines the value of the attribute. The value depends on what kind of attribute this is. type same type as value Convert the value to another type. rewrite [] Rewrite a mapped attribute to another value (May also be done using a scripted attribute). filter [] Chain of predefined string filters to apply unwind null Unwind a list and operate attribute options on each list element. skip false If true the attribute gets ignored. This may be useful if an attribute is only used for an object relation creation or relation context. map Define an object relation mapping to another collection. Automatically create DataObjectReations. writeonly false Writeonly flag may be set to true for attributes which get not returned by endpoints (writeonly attributes).","title":"Mapping"},{"location":"resources/workflows/#name","text":"The name is required and defines the name of the destination attribute name. Note Important, DataObject attributes are usually in the data container. For example, lets define an attribute from an active directory source endpoint and map the samAccountName to our DataObject. map: - name: data.username from: samAccountName The data. prefix is required since a DataObjects data is placed within a data container. See an example of a DataObject here .","title":"Name"},{"location":"resources/workflows/#kind","text":"There are three different attribute kinds while map is the default one. Kind Description map The value will hold the name of the source attribute from which value will be taken. The value must be string in this case since all attribute names are strings. static The value is a static value. It may be any supported type. script The value is a javascript executed by the V8 engine. The result must set by calling core.result() while the current DataObject is accessible using core.object .","title":"Kind"},{"location":"resources/workflows/#ensure_1","text":"The ensure type on a attributes knows one more type merge compared to workflow itself. Ensure Description exists The attribute gets only mapped if it does not exists yet. last The attribute gets mapped with the latest value. absent The attribute gets removed. merge The attributes get merged, only useful if the value is an array/list. Defines mighty scipted attributes. The engine executes JavaScript and used the result of core.result() as the value for the attribute.","title":"Ensure"},{"location":"resources/workflows/#type","text":"By default the source attributes type will be untouched. However you may convert the value to another type. The same attribute types as defined in a collection schema are available. Note The type conversion takes place at the very end of the attribute mapping.","title":"Type"},{"location":"resources/workflows/#rewrite","text":"You may use rewrite rules to rewrite a value. Rewrite rules may either be of static matching using from or a regex ( PCRE ) matching using match . The rewrite processor stops as soon as either from or a regex match match the given attributes value. Example: map: - name: entrydn kind: script value: core.result('uid='+core.object.data.username+',ou='+core.object.department+',o=company,dc=example,dc=org') rewrite: - from: uid=admin,ou=admins,o=company,dc=example,dc=org to: uid=Administrator,ou=admins,o=company,dc=example,dc=org - match: #uid=([^,]),ou=hr,o=company,dc=example,dc=org# to: uid=$2,ou=secretariat,o=company,dc=example,dc=org - match: #uid=([^,]),ou=assistence,o=company,dc=example,dc=org# to: uid=$2,ou=secretariat,o=company,dc=example,dc=org Note Rewrite rules get execute once the value is determined from either from,value or script but before a possible type conversion. You may achive the same using scripted attributes. But rewrite rules are a more readable way and should be the preferred choice if you need to rewrite any values.","title":"Rewrite"},{"location":"resources/workflows/#unwind","text":"Using unwind you may operate on each element within a list attribute. You may apply each attribute mapping option to a unwind operator. For example, we have a DataObject with an attribute adresses which is a list of adresses and we want to map all streets to an attribute called street. DataObject: kind: DataObject collection: people data: firstName: John lastName: Meyer adresses: - street: First street 20 zip: 33445 city: New York - street: Company street 38 zip: 3445 city: Zurich The goal is to get an attribute called street with the value ['First street 20', 'Company street 38'] . Lets unwind the attribute adresses and grab the value with from . Note While unwindig the each list value gets available at root . map: - name: street value: data.adresses unwind: from: root.street The same is achievable using scripted attributes, but like rewrite rules, unwinding may be the preferrable solution. ### Map Map is particulary useful to automatically create DataObjectRelations between DataObjects. DataObjectRelations represent a relationship between two (or more) DataObjects. Those DataObject may be from different collections and/or namespaces. Lets asume we have a collection named accounts and one named groups . We would like to import LDAP objects into both of them. Into accounts we import person objects and into group group objects. While importing we'd like to automatically create tubee DataObjectRelations between group and group members. Lets asume those LDAP group objects have an attribute member which is a list of user distinguished names. To automatically create a relationship we need to specify the map keyword and pointing the destination collection to accounts and the key which gets used to identify the destination account object to data.dn (data.dn will hold the account dn). Optionally we set an attribute ou as context. Example: map: - name: data.member value: member map: collection: accounts to: data.dn context: - ou skip: true - name: data.ou from: ou skip: true This mapping will automatically try to create DataObjectRelations between those two collections. Option Default Description collection required The name of the destination collection. to required The name of the DataObject in the destination collection to use as relationship reference. (Usually you will ned to specify the attribute within data. (for example data.id)). ensure last By default the relationship gets created and updated. You may set ensure to exists or absent while on exists the relation will not get updated (for example if context data gets changed). If absent the relation gets removed. context empty list A list of attributes to use as context attributes. (Note that you can also use attributes which have skip: true set.)","title":"Unwind"},{"location":"resources/workflows/#skip","text":"Skip is by default false. An attribute which has skip on true is declared as a virtual attribute and never gets written anywhere. However a skip: true attribute may be useful if it gets used to write a DataObjectRelation context (See Map ).","title":"Skip"},{"location":"resources/workflows/#writeonly","text":"A password attribute is an example for such attributes. Passwords usually may be writeable but get not returned. While writeonly is set to true and DataObject already exists on the endpoint, the attribute does not get written. writeonly: true attributes may only get written during object creation. Note that it does not matter what value ensure holds while the attribute is set on writeonly and the DataObject already exists.","title":"Writeonly"},{"location":"resources/workflows/#filter","text":"Specify an optional chain of filters to apply as string filters: Alnum Alpha BaseName Digits Dir HtmlEntities RealPath StringPrefix StringSuffix StringToLower StringToUpper StringTrim StripNewlines StripTags UriNormalize","title":"Filter"},{"location":"sdk/nodejs/","text":"tubee node.js SDK with typescript support Provides a node.js SDK for tubee. Including typescript definition. Note This SDK is mostly generated from the tubee OpenAPI specs. Install npm install --save @gyselroth/tubee-sdk-node Usage Example request const { CoreV1Api, HttpBasicAuth} = require('@gyselroth/tubee-sdk-node'); var server = 'https://localhost:8090'; var sdk = new CoreV1Api(server); var basic = new HttpBasicAuth(); basic.username = 'admin'; basic.password = 'admin'; sdk.setDefaultAuthentication(basic); sdk.getNamespaces().then((response) = { console.log(response.body); }).catch((error) = { console.log(error); });","title":"tubee node.js SDK with typescript support"},{"location":"sdk/nodejs/#tubee-nodejs-sdk-with-typescript-support","text":"Provides a node.js SDK for tubee. Including typescript definition. Note This SDK is mostly generated from the tubee OpenAPI specs.","title":"tubee node.js SDK with typescript support"},{"location":"sdk/nodejs/#install","text":"npm install --save @gyselroth/tubee-sdk-node","title":"Install"},{"location":"sdk/nodejs/#usage","text":"","title":"Usage"},{"location":"sdk/nodejs/#example-request","text":"const { CoreV1Api, HttpBasicAuth} = require('@gyselroth/tubee-sdk-node'); var server = 'https://localhost:8090'; var sdk = new CoreV1Api(server); var basic = new HttpBasicAuth(); basic.username = 'admin'; basic.password = 'admin'; sdk.setDefaultAuthentication(basic); sdk.getNamespaces().then((response) = { console.log(response.body); }).catch((error) = { console.log(error); });","title":"Example request"},{"location":"server/","text":"tubee tubee is a data management engine with proxy capabilities for other services and its core feature is the possibility to synchronize data between multiple services (endpoints) such as databases, ldap server, file formats, web applications and more. Everything can be fully automated using tubee. You may specify different synchronization workflows and defined custom attribute mappings. Create scripted attributes, conditions, synchronization jobs and more. tubee can be used to automatically synchronize your objecs between multiple endpoints. This can be everything in its nature, for example synchronize user accounts from an XML file to Active Directory and MongoDB. Do whatever you have to do. Features Namespace support Supports Import/Export to and from various different technologies Resource versioning Full asynchronous sync jobs Time triggered sync jobs RBAC Proxy for supported endpoints (Access endpoints via the tubee layer) Query rewriting for different endpoints (Query data from endpoints with the same query language) Attribute mapping between tubee and endpoints Attribtue scripting, rewriting and more Attribute map workflows Full featured OpenAPI v2 REST API SDK's for 3rt party software Published as debian package, tar archive and docker image Full support for a cloud native deployment like on Kubernetes Perfectly scalable for your needs Console client for Linux, Windows and OSX Endpoints Endpoints LDAP (OpenLDAP, ActiveDirectory and other LDAP server) Various SQL Databases (PDO, All relational SQL database engines) Native MySQL/MariaDB MongoDB Moodle balloon ODataRest (Like Microsoft online (Office365 and more)) XML (via different storage backends, see Storage drivers) CSV (via different storage backends, see Storage drivers) JSON (via different storage backends, see Storage drivers) Images (via different storage backends, see Storage drivers) Ucs (Univention Corporate Server) Storage drivers for data formats: LocalFilesystem balloon cloud server SMB (Windows/Samba share via smb) Stream (HTTP,FTP and more) Documentation Visit https://tubee.readthedocs.io to get started! Changelog A changelog is available here . Contribute We are glad that you would like to contribute to this project. Please follow the given terms .","title":"tubee"},{"location":"server/#tubee","text":"tubee is a data management engine with proxy capabilities for other services and its core feature is the possibility to synchronize data between multiple services (endpoints) such as databases, ldap server, file formats, web applications and more. Everything can be fully automated using tubee. You may specify different synchronization workflows and defined custom attribute mappings. Create scripted attributes, conditions, synchronization jobs and more. tubee can be used to automatically synchronize your objecs between multiple endpoints. This can be everything in its nature, for example synchronize user accounts from an XML file to Active Directory and MongoDB. Do whatever you have to do.","title":"tubee"},{"location":"server/#features","text":"Namespace support Supports Import/Export to and from various different technologies Resource versioning Full asynchronous sync jobs Time triggered sync jobs RBAC Proxy for supported endpoints (Access endpoints via the tubee layer) Query rewriting for different endpoints (Query data from endpoints with the same query language) Attribute mapping between tubee and endpoints Attribtue scripting, rewriting and more Attribute map workflows Full featured OpenAPI v2 REST API SDK's for 3rt party software Published as debian package, tar archive and docker image Full support for a cloud native deployment like on Kubernetes Perfectly scalable for your needs Console client for Linux, Windows and OSX","title":"Features"},{"location":"server/#endpoints","text":"Endpoints LDAP (OpenLDAP, ActiveDirectory and other LDAP server) Various SQL Databases (PDO, All relational SQL database engines) Native MySQL/MariaDB MongoDB Moodle balloon ODataRest (Like Microsoft online (Office365 and more)) XML (via different storage backends, see Storage drivers) CSV (via different storage backends, see Storage drivers) JSON (via different storage backends, see Storage drivers) Images (via different storage backends, see Storage drivers) Ucs (Univention Corporate Server) Storage drivers for data formats: LocalFilesystem balloon cloud server SMB (Windows/Samba share via smb) Stream (HTTP,FTP and more)","title":"Endpoints"},{"location":"server/#documentation","text":"Visit https://tubee.readthedocs.io to get started!","title":"Documentation"},{"location":"server/#changelog","text":"A changelog is available here .","title":"Changelog"},{"location":"server/#contribute","text":"We are glad that you would like to contribute to this project. Please follow the given terms .","title":"Contribute"},{"location":"server/changelog/","text":"1.0.0-beta54 Maintainer : Raffael Sahli Date : Thu Dec 05 10:04:21 CEST 2019 Bugfixes Links against taskscheduler v3.2.2 (progress rate to 100% after finish) 1.0.0-beta53 Maintainer : Raffael Sahli Date : Wed Dec 04 17:14:21 CEST 2019 Bugfixes Links against taskscheduler v3.2.1 (progress rate limit fix) Fixes exception logging 1.0.0-beta52 Maintainer : Raffael Sahli Date : Wed Dec 04 15:58:21 CEST 2019 Bugfixes Do not send notifications from child processes 1.0.0-beta51 Maintainer : Raffael Sahli Date : Tue Dec 03 16:31:21 CEST 2019 Bugfixes Job notification includes errors from child processes Do not cancel processes which have status = 3 after a job gets disabled Features Processes with estimated time to finish Sync jobs with progress information Endpoints can now count their EndpointObjects 1.0.0-beta50 Maintainer : Raffael Sahli Date : Fri Oct 11 13:55:22 CEST 2019 CORE: [FIX] TypeError: Argument 2 passed to Tubee\\Endpoint\\AbstractRest::getResourceId() must implement interface Tubee\\EndpointObject\\EndpointObjectInterface or be null, array given 1.0.0-beta49 Maintainer : Raffael Sahli Date : Wed Oct 09 13:04:22 CEST 2019 CORE: [FIX] Catch throwable errors during checking endpoint status CORE: [FIX] Added upgrade migration for SmbStorage (workgroup) 1.0.0-beta48 Maintainer : Raffael Sahli Date : Wed Oct 09 10:14:21 CEST 2019 CORE: [FIX] The default XMLEndpoint filter is now //node_name while node_name is the configured node_name of the endpoint options (By default it is row ). CORE: [FIX] SmbStorage openWriteStream() does not truncate files anymore 1.0.0-beta47 Maintainer : Raffael Sahli Date : Wed Sep 30 09:52:21 CEST 2019 CORE: [FIX] Error: Call to undefined method mysqli_result::fetch() in /usr/share/tubee/src/lib/Endpoint/Mysql.php:105 1.0.0-beta46 Maintainer : Raffael Sahli Date : Wed Sep 25 14:42:20 CEST 2019 CORE: [FIX] Fixes default ordering (created by descending) 1.0.0-beta45 Maintainer : Raffael Sahli Date : Wed Sep 25 12:21:20 CEST 2019 CORE: [FIX] Sort operation used more than the maximum 33554432 bytes of RAM. Add an index, or specify a smaller limit. There is now no sorting during stream requests. CORE: [FIX] Errors during streams are now handled as StreamError and be returned to the requested as such. 1.0.0-beta44 Maintainer : Raffael Sahli Date : Fr Sep 20 16:41:20 CEST 2019 CORE: [FIX] Error: Call to undefined method mysqli_stmt::fetch_assoc() in /usr/share/tubee/src/lib/Endpoint/Mysql.php:77 1.0.0-beta43 Maintainer : Raffael Sahli Date : Fr Sep 20 15:47:20 CEST 2019 CORE: [FIX] ArgumentCountError: Wrong parameter count for mysqli_stmt::bind_param() in /usr/share/tubee/src/lib/Endpoint/Mysql/Wrapper.php:159 CORE: [FEATURE] Support query dsl for PdoEndpoint and MysqlEndpoint 1.0.0-beta42 Maintainer : Raffael Sahli Date : Wed Sep 11 16:20:21 CEST 2019 CORE: [FIX] ErrorException: Undefined property: PDOStatement::$num_rows in /usr/share/tubee/src/lib/Endpoint/Pdo.php:84 CORE: [CHANGE] Use prepared stmts for fetching mysql/pdo endpoint data, filter column/table names CORE: [FIX] Fixes endpoints MongodbEndpoint/PdoEndpoint/MysqlEndpoint as destination ep 1.0.0-beta41 Maintainer : Raffael Sahli Date : Mon Sep 09 10:09:21 CEST 2019 CORE: [FIX] Fixes unusable MysqlEndpoint (Could not be initialized) 1.0.0-beta40 Maintainer : Raffael Sahli Date : Fri Aug 16 10:57:23 CEST 2019 CORE: [FIX] Job includes last process status from wrong namespace CORE: [FIX] Remove all processors from the logger before a new sync jobs starts CORE: [CHANGE] Removed $natural mongodb sorting (replaced with indexed changed: 1 sort by default), ($natural sorting does not use indices ans is therefore too slow) CORE: [CHANGE] Changed log resource structure, Log resources have now a more identical structure than other resources CORE: [FIX] DOMXPath::query(): Invalid expression at /srv/www/tubee/src/lib/Endpoint/Xml.php:218 CORE: [FIX] Log error if xml yields an invalid EndpointObject and continue with the next CORE: [FEATURE] Added support for $exists query to the XmlEndpoint CORE: [FIX] Watch streams now include updates and removals CORE: [FIX] Watch dataobjects Fatal error: Method StreamIterator\\StreamIterator toString() must not throw an exception, caught TypeError: Argument 1 passed to Tubee\\DataObject\\Factory::build() must be of the type array CORE: [FIX] Do not drop fields if skip is true #56 1.0.0-beta39 Maintainer : Raffael Sahli Date : Thu Jul 18 10:36:23 CEST 2019 CORE: [FIX] A Throwable exception (TypeError) might lead to multiple loggers and therefore the wrong process id gets attached to logs CORE: [FIX] MicrosoftGraphEndpoint: Remove group member/owner ends in \"Write requests are only supported on contained entities\" CORE: [FIX] MicrosoftGraphEndpoint: Resolve all group members/owners (limit of 100 resources) CORE: [FIX] MicrosoftGraphEndpoint: Do not throw exception if /groups/{group}/team fails CORE: [CHANGE] Add attribute type #34 1.0.0-beta38 Maintainer : Raffael Sahli Date : Tue Jul 16 14:28:23 CEST 2019 CORE: [FIX] GRAPH API (ODataRest) returns a 404 if an object was not found from id=x filter 1.0.0-beta37 Maintainer : Raffael Sahli Date : Tue Jul 16 09:24:22 CEST 2019 CORE: [FIX] Member batch result verify team via status and not code CORE: [FIX] Validate Process/Job filter before register/update a new one CORE: [FIX] Validate Endpoint filter_all/filter_new before register/update a new one 1.0.0-beta36 Maintainer : Raffael Sahli Date : Mon Jul 15 15:44:11 CEST 2019 CORE: [FIX] Fix DataObject relations to array conversion 1.0.0-beta35 Maintainer : Raffael Sahli Date : Mon Jul 15 13:48:11 CEST 2019 CORE: [FIX] Fix order if resources were retrieved via api CORE: [CHANGE] Cache resolved relations during workflow executions 1.0.0-beta34 Maintainer : Raffael Sahli Date : Mon Jul 15 10:45:14 CEST 2019 CORE: [FIX] Do not count objects during fetch if no limit was given 1.0.0-beta33 Maintainer : Raffael Sahli Date : Mon Jul 15 10:44:11 CEST 2019 CORE: [FIX] Performance fix during fetching relations 1.0.0-beta32 Maintainer : Raffael Sahli Date : Wed Jul 11 15:42:11 CEST 2019 CORE: [FIX] last_sync/last_successful_sync have an old timestamp #53 1.0.0-beta31 Maintainer : Raffael Sahli Date : Tue Jul 09 09:04:11 CEST 2019 CORE: [FEATURE] Added MicrosoftGraph endpoint with support for groups and teams 1.0.0-beta30 Maintainer : Raffael Sahli Date : Fri Jun 28 09:04:11 CEST 2019 CORE: [FIX] Import DataObject (update) does not update last_sync to current timestamp 1.0.0-beta29 Maintainer : Raffael Sahli Date : Thu Jun 27 11:22:11 CEST 2019 CORE: [CHANGE] Includes exception for failed DataObject syncs CORE: [CHANGE] DataObject endpoint garbage is set to true if the DataObject does not exists on the endpoint 1.0.0-beta28 Maintainer : Raffael Sahli Date : Tue Jun 18 13:45:12 CEST 2019 CORE: [FIX] Fixes stream 1.0.0-beta27 Maintainer : Raffael Sahli Date : Tue Jun 18 11:03:12 CEST 2019 CORE: [FIX] Fixes watch changeStream 1.0.0-beta26 Maintainer : Raffael Sahli Date : Mon Jun 17 16:57:12 CEST 2019 CORE: [FIX] DataObjectRealtion context gets now changed if the context changes during sync 1.0.0-beta25 Maintainer : Raffael Sahli Date : Mon Jun 17 09:23:12 CEST 2019 CORE: [FIX] Added new logs mongodb index (parent, namespace) which drastically increase log request performance DOCS: [CHANGE] Added permalink extension (anchors) CORE: [FEATURE] Added predefined filters to workflow attributes CORE: [CHANGE] Update endpoint status of DataObject #49 1.0.0-beta24 Maintainer : Raffael Sahli Date : Mon Jun 17 09:23:12 CEST 2019 CORE: [FIX] Do not sort if sort is equal {$natual: 1}, this is a default anyway but will slow down the query if mentioned 1.0.0-beta23 Maintainer : Raffael Sahli Date : Wed Jun 12 14:01:12 CEST 2019 API: [FIX] error\":\"TypeError\",\"message\":\"Argument 3 passed to Tubee\\DataObjectRelation\\Factory::watch() must be of the type boolean, array given, called in /usr/share/tubee/src/lib/Rest/v1/ObjectRelations.php on line 80 1.0.0-beta22 Maintainer : Raffael Sahli Date : Wed Jun 12 14:01:12 CEST 2019 API: [FIX] fixes process data Tubee\\Rest\\Middlewares\\ExceptionHandler,ERROR]: uncaught exception Unexpected property: data 1.0.0-beta21 Maintainer : Raffael Sahli Date : Fri Jun 07 09:01:12 CEST 2019 CORE: [FIX] Add workflow with no data ends in Undefined index exception #44 API: [CHANGE] Added core.v1 prefix to all requests and resources in openapi/swagger schemas CORE: [CHANGE] Ucs endpoint must check search response for equality #45 API: [CHANGE] Added readonly flags to Job/Process/Endpoint,DataObjectRelation,DataObject status fieldss 1.0.0-beta20 Maintainer : Raffael Sahli Date : Mon Jun 03 15:50:12 CEST 2019 CORE: [FIX] Using own log formatter for mongodb to encode most context as json since context may contain invalid mongodb field names ($ prefix or .) 1.0.0-beta19 Maintainer : Raffael Sahli Date : Mon Jun 03 13:50:11 CEST 2019 CORE: [FIX] Always include $dn$ in Ucs change() CORE: [FIX] factories watch() include default filter like getAll() 1.0.0-beta18 Maintainer : Raffael Sahli Date : Wed May 29 11:50:12 CEST 2019 CORE: [FIX] Skip objects if build() returns null 1.0.0-beta17 Maintainer : Raffael Sahli Date : Tue May 28 16:49:12 CEST 2019 CORE: [FIX] Trying to get property 'relations' of non-object 1.0.0-beta16 Maintainer : Raffael Sahli Date : Thu May 23 10:26:12 CEST 2019 CORE: [FIX] encode found export object, fixes MongoDB\\Driver\\Exception\\InvalidArgumentException: invalid document for insert: keys cannot begin with \"$\" CORE: [FIX] added missing simulate field to Job resource in swagger specs 1.0.0-beta15 Maintainer : Raffael Sahli Date : Wed May 22 12:26:12 CEST 2019 CORE: [FIX] do not throw Exception\\ImportConditionNotMet if multiple data objects were found, sync relations first and log a warning instead CORE: [FIX] Wrong debug log: total counter is less than the current DataObject #40 CORE: [FIX] pdo endpoint (mssql) generates wrong filter #39 CORE: [FIX] Do not throw an exception during query for an non existing mssql field #38 1.0.0-beta14 Maintainer : Raffael Sahli Date : Wed May 15 12:26:12 CEST 2019 CORE: [FIX] undefined class constant self::COLLECTION_NAME in Tubee\\DataObjectRelation\\Factory 1.0.0-beta13 Maintainer : Raffael Sahli Date : Thu May 09 15:51:14 CEST 2019 CORE: [FIX] Error: Cannot access protected property Tubee\\DataObjectRelation\\Factory::$logger CORE: [FIX] Error: Cannot access protected property Tubee\\DataObjectRelation\\Factory::$resource_factory CORE: [FIX] MongoDB\\Driver\\Exception\\InvalidArgumentException: invalid document for insert: keys cannot contain \".\": 1.0.0-beta12 Maintainer : Raffael Sahli Date : Wed May 08 17:06:12 CEST 2019 CORE: [FIX] TypeError: Argument 2 passed to Tubee\\Async\\Sync::export() must be of the type array, null given 1.0.0-beta11 Maintainer : Raffael Sahli Date : Wed May 08 15:06:12 CEST 2019 CORE: [CHANGE] Set garbage endpoint flag to true if object gets removed from endpoint during export absent workflow CORE: [CHANGE] ldap entrydn from mapping gets normalized as well (all lowercase) CORE: [FIX] MongoDB\\Driver\\Exception\\BulkWriteException: WiredTigerIndex::insert: key too large to index, failing 1134 CORE: [CHANE] throw Tubee\\Workflow\\Exception\\ImportConditionNotMet if source data objects are not unique CORE: [FIX] sort operation does not work for sorting data object, endpoint, collection resources CORE: [FIX] Method StreamIterator\\StreamIterator::__toString() must not throw an exception, caught ErrorException: Undefined index: created in API: [CHANGE] If authentication failed a 401 gets returned instead of a 500 API: [CHANGE] filter is now a json encoded object in Process and Job resources CORE: [FIX] skip garbage collection if a filtered process was issued 1.0.0-beta10 Maintainer : Raffael Sahli Date : Tue May 07 12:06:12 CEST 2019 CORE: [FIX] Undefined property: Tubee\\DataObjectRelation\\Factory::$logger in /usr/share/tubee/src/lib/DataObjectRelation/Factory.php:160 CORE: [FIX] nullable endpoint result after a seccond sync 1.0.0-beta9 Maintainer : Raffael Sahli Date : Sun Apr 18 11:34:01 CEST 2019 CORE: [FIX] Ldap auth adapter dremscape dependency is no correctly recreated for every ldap auth adapter CORE: [FIX] Allow calls to /api and /api/v1 for everyone if authenticated 1.0.0-beta8 Maintainer : Raffael Sahli Date : Sub Apr 14 15:04:01 CEST 2019 CORE: [FIX] automatically drop unresolvable relations and do not throw exception if such events occur during relation resolving CORE: [CHANGE] Add index for field name during collection creation CORE: [CHANGE] ensure index for import fields after updating endpoint CORE: [FIX] workflow priority ordner, 0 first CORE: [FIX] fixed getAll during ldap query if filter_all is null CORE: [FIX] fixed ldap endpoint non utf-8 data encoding CORE: [FIX] normalize ldap dn (ignore case of dn attribute parts) 1.0.0-beta7 Maintainer : Raffael Sahli Date : Wed Apr 11 17:11:01 CEST 2019 CORE: [FIX] attributes of type array and unwind will now be properly converted to a list CORE: [FIX] fixed cancel process after setting job active to false 1.0.0-beta6 Maintainer : Raffael Sahli Date : Wed Apr 11 15:51:01 CEST 2019 CORE: [CHANGE] attribute map type array converts to real numeric array CORE: [FIX] Undefined index: data in PATCH update job CORE: [CHANGE] creating dataobject relations on thy fly may now match multiple objects to create relations to 1.0.0-beta5 Maintainer : Raffael Sahli Date : Wed Apr 11 10:51:01 CEST 2019 CORE: [CHANGE] log endpoint object during import/export workflows CORE: [FIX] ODataRest endpoint does not required specific declaration of the id CORE: [FIX] LdapEndpoint entrydn is now always lowercase CORE: [FIX] ignore ldap entrydn in diff CORE: [FEATURE] new option active for jobs. jobs may be enabled/disabled. 1.0.0-beta4 Maintainer : Raffael Sahli Date : Fri Apr 05 16:51:01 CEST 2019 PACKAGING: [FIX] fixed TUBEE_CONFIG_DIR in docker image to /etc/tubee API: [FIX] Argument 5 passed to Tubee\\DataObject\\Factory::watch() must be of the type integer or null, boolean given API: [FIX] Argument 2 passed to Tubee\\DataObjectRelation\\Factory::watch() must implement interface MongoDB\\BSON\\ObjectIdInterface or be null, array given API: [FIX] Argument 6 passed to Tubee\\Resource\\Factory::watchFrom() must be of the type integer or null, object given, API: [FIX] Added default empty array to Workflow map.context CORE: [FIX] Invalid json (especially filter_one and filter_all) results now in Exception\\InvalidJson CORE: [FEATURE] Added new attribute map option writeonly to only apply attributes initially if true 1.0.0-beta3 Maintainer : Raffael Sahli Date : Wed Apr 03 16:01:01 CEST 2019 API: [FIX] Added route /api to /api/v1 CORE: [FIX] Fixed route/acl middleware order CORE: [CHANGE] upgraded micro-auth to latest alpha which fixes Adapter\\Basic\\Ldap identifier issue CORE: [FIX] user password can now be changed correctly CORE: [CHANGE] Invalid secret key now responds with Tubee\\Secret\\Exception\\SecretNotResolvable instead Tubee\\Exception API: [CHANGE] Endpoints with default identifiers specify those now in the openapi specs 1.0.0-beta2 Maintainer : Raffael Sahli Date : Mon Mar 25 15:14:01 CET 2019 TESTING: [CHANGE] Added new xml endpoint unit tests PACKAGING: [CHANGE] Dev docker container now sets TUBEE_SECRET_KEY PACKAGING: [FIX] fixes no make dep npm PACKAGING: [CHANGE] Dockerfile and Dockerfile-dev are no part of the server repo itself PACKAGING: [CHANGE] docker images now inherits from gyselroth/tubee:php7.2-fpm-v8js which already includes v8js DOCS: [CHANGE] Various fixes CORE: [FIX] Do not block GET /logs requests if log response from MongoDB is empty (do not use natural sorting) CORE: [FIX] Xml, Csv validators merge defaults before validation CORE: [FIX] fixed ldap filter concat for filter_all and custom query CORE: [CHANGE] StorageInterface::syncWriteStream() implementations do now fclose() the resource CORE: [FEATURE] Enhanced query transformation for xml endpoint, query to xpath including $and, $or, $gt, $gte, $lt, $lte, $ne CORE: [FIX] Fixes issue due xml object change with diff type AttributeMapInterface::ACTION_ADD CORE: [FIX] resource validation now takes place with mounted secrets CORE: [CHANGE] Replaced resource validators with Garden\\Schema\\Schema OpenAPI v3 validation CORE: [CHANGE] Added OpenAPI v3 specs besides swagger v2 CORE: [FEATURE] Added new resource type GarbageWorkflow which replaces the need to write a scripted condition and check for garbage run CORE: [FIX] Fixed workflow cleanup execution CORE: [FEATURE] Remove DataObjectRelation with GarbageWorkflows CORE: [CHANGE] CoreInstallation delta now initializes required MongoDB replset if this has not been done yet CORE: [CHANGE] Possibility to automatically remove DataObjectRelations during GarbageWorkflows (set map[].ensure to absent) CORE: [CHANGE] Refactoring Workflow into Workflow\\ImportWorkflow and Workflow\\ExportWorkflow CORE: [CHANGE] Added TUBEE_CACHE_ADAPTER and TUBEE_LOG_LEVEL env variables to default container config CORE: [CHANGE] All resource factories now depend on Resource\\Factory which itself uses a Psr cache for resource validation CORE: [FIX] flush: true results in \"TypeError: Argument 1 passed to Tubee\\DataObject\\Factory::deleteAll() must implement interface Tubee\\Collection\\CollectionInterface, boolean given\" CORE: [FEATURE] Added -f to cli jobs (flush queue) CORE: [FEATURE] Added (bool) skip to attribute mapping to skip attributes to map CORE: [CHANGE] endpoint filter_all and filter_one use the tubee (mongodb) dql now instead filters in endpoint specific formats CORE: [FEATURE] filter_one and filter_all can now be used for Csv and Json endpoints (Note that performance is not optimal since those formats do not have a propper query language and neither now indexing) CORE: [CHANGE] Added Endpoint\\LoggerTrait to apply generic endpoint operation logging CORE: [FIX] readOnly attributes get stripped out from request CORE: [FIX] binary values in Endpoint\\Ldap get base64 encoded CORE: [FEATURE] Possibility to set context data within map definition in worklow API: [FIX] uncaught exception: Argument 4 passed to Tubee\\Rest\\v1\\Processes::delete() must implement interface MongoDB\\BSON\\ObjectIdInterface API: [FIX] uncaught exception: Argument 1 passed to Tubee\\Secret\\Factory::getOne() must implement interface Tubee\\ResourceNamespace\\ResourceNamespaceInterface, string given at POST /api/v1/secrets API: [FIX] uncaught exception: Undefined variable: job] [object] (ErrorException(code: 0): Undefined variable: job at POST /api/v1/jobs API: [FIX] Added ImageEndpoint to openapi v3 specs API: [FIX] fixed max execution time of 5min for watch stream requests API: [FIX] Added reaOnly flags to openapi spec for readonly attributes (like created, changed, version) API: [FIX] Exception middleware catches now throwables instead just exceptions only 1.0.0-beta1 Maintainer : Raffael Sahli Date : Fri Jan 25 17:14:01 CET 2019 Initial beta relase v1.0.0-beta1","title":"Changelog"},{"location":"server/changelog/#100-beta54","text":"Maintainer : Raffael Sahli Date : Thu Dec 05 10:04:21 CEST 2019","title":"1.0.0-beta54"},{"location":"server/changelog/#bugfixes","text":"Links against taskscheduler v3.2.2 (progress rate to 100% after finish)","title":"Bugfixes"},{"location":"server/changelog/#100-beta53","text":"Maintainer : Raffael Sahli Date : Wed Dec 04 17:14:21 CEST 2019","title":"1.0.0-beta53"},{"location":"server/changelog/#bugfixes_1","text":"Links against taskscheduler v3.2.1 (progress rate limit fix) Fixes exception logging","title":"Bugfixes"},{"location":"server/changelog/#100-beta52","text":"Maintainer : Raffael Sahli Date : Wed Dec 04 15:58:21 CEST 2019","title":"1.0.0-beta52"},{"location":"server/changelog/#bugfixes_2","text":"Do not send notifications from child processes","title":"Bugfixes"},{"location":"server/changelog/#100-beta51","text":"Maintainer : Raffael Sahli Date : Tue Dec 03 16:31:21 CEST 2019","title":"1.0.0-beta51"},{"location":"server/changelog/#bugfixes_3","text":"Job notification includes errors from child processes Do not cancel processes which have status = 3 after a job gets disabled","title":"Bugfixes"},{"location":"server/changelog/#features","text":"Processes with estimated time to finish Sync jobs with progress information Endpoints can now count their EndpointObjects","title":"Features"},{"location":"server/changelog/#100-beta50","text":"Maintainer : Raffael Sahli Date : Fri Oct 11 13:55:22 CEST 2019 CORE: [FIX] TypeError: Argument 2 passed to Tubee\\Endpoint\\AbstractRest::getResourceId() must implement interface Tubee\\EndpointObject\\EndpointObjectInterface or be null, array given","title":"1.0.0-beta50"},{"location":"server/changelog/#100-beta49","text":"Maintainer : Raffael Sahli Date : Wed Oct 09 13:04:22 CEST 2019 CORE: [FIX] Catch throwable errors during checking endpoint status CORE: [FIX] Added upgrade migration for SmbStorage (workgroup)","title":"1.0.0-beta49"},{"location":"server/changelog/#100-beta48","text":"Maintainer : Raffael Sahli Date : Wed Oct 09 10:14:21 CEST 2019 CORE: [FIX] The default XMLEndpoint filter is now //node_name while node_name is the configured node_name of the endpoint options (By default it is row ). CORE: [FIX] SmbStorage openWriteStream() does not truncate files anymore","title":"1.0.0-beta48"},{"location":"server/changelog/#100-beta47","text":"Maintainer : Raffael Sahli Date : Wed Sep 30 09:52:21 CEST 2019 CORE: [FIX] Error: Call to undefined method mysqli_result::fetch() in /usr/share/tubee/src/lib/Endpoint/Mysql.php:105","title":"1.0.0-beta47"},{"location":"server/changelog/#100-beta46","text":"Maintainer : Raffael Sahli Date : Wed Sep 25 14:42:20 CEST 2019 CORE: [FIX] Fixes default ordering (created by descending)","title":"1.0.0-beta46"},{"location":"server/changelog/#100-beta45","text":"Maintainer : Raffael Sahli Date : Wed Sep 25 12:21:20 CEST 2019 CORE: [FIX] Sort operation used more than the maximum 33554432 bytes of RAM. Add an index, or specify a smaller limit. There is now no sorting during stream requests. CORE: [FIX] Errors during streams are now handled as StreamError and be returned to the requested as such.","title":"1.0.0-beta45"},{"location":"server/changelog/#100-beta44","text":"Maintainer : Raffael Sahli Date : Fr Sep 20 16:41:20 CEST 2019 CORE: [FIX] Error: Call to undefined method mysqli_stmt::fetch_assoc() in /usr/share/tubee/src/lib/Endpoint/Mysql.php:77","title":"1.0.0-beta44"},{"location":"server/changelog/#100-beta43","text":"Maintainer : Raffael Sahli Date : Fr Sep 20 15:47:20 CEST 2019 CORE: [FIX] ArgumentCountError: Wrong parameter count for mysqli_stmt::bind_param() in /usr/share/tubee/src/lib/Endpoint/Mysql/Wrapper.php:159 CORE: [FEATURE] Support query dsl for PdoEndpoint and MysqlEndpoint","title":"1.0.0-beta43"},{"location":"server/changelog/#100-beta42","text":"Maintainer : Raffael Sahli Date : Wed Sep 11 16:20:21 CEST 2019 CORE: [FIX] ErrorException: Undefined property: PDOStatement::$num_rows in /usr/share/tubee/src/lib/Endpoint/Pdo.php:84 CORE: [CHANGE] Use prepared stmts for fetching mysql/pdo endpoint data, filter column/table names CORE: [FIX] Fixes endpoints MongodbEndpoint/PdoEndpoint/MysqlEndpoint as destination ep","title":"1.0.0-beta42"},{"location":"server/changelog/#100-beta41","text":"Maintainer : Raffael Sahli Date : Mon Sep 09 10:09:21 CEST 2019 CORE: [FIX] Fixes unusable MysqlEndpoint (Could not be initialized)","title":"1.0.0-beta41"},{"location":"server/changelog/#100-beta40","text":"Maintainer : Raffael Sahli Date : Fri Aug 16 10:57:23 CEST 2019 CORE: [FIX] Job includes last process status from wrong namespace CORE: [FIX] Remove all processors from the logger before a new sync jobs starts CORE: [CHANGE] Removed $natural mongodb sorting (replaced with indexed changed: 1 sort by default), ($natural sorting does not use indices ans is therefore too slow) CORE: [CHANGE] Changed log resource structure, Log resources have now a more identical structure than other resources CORE: [FIX] DOMXPath::query(): Invalid expression at /srv/www/tubee/src/lib/Endpoint/Xml.php:218 CORE: [FIX] Log error if xml yields an invalid EndpointObject and continue with the next CORE: [FEATURE] Added support for $exists query to the XmlEndpoint CORE: [FIX] Watch streams now include updates and removals CORE: [FIX] Watch dataobjects Fatal error: Method StreamIterator\\StreamIterator toString() must not throw an exception, caught TypeError: Argument 1 passed to Tubee\\DataObject\\Factory::build() must be of the type array CORE: [FIX] Do not drop fields if skip is true #56","title":"1.0.0-beta40"},{"location":"server/changelog/#100-beta39","text":"Maintainer : Raffael Sahli Date : Thu Jul 18 10:36:23 CEST 2019 CORE: [FIX] A Throwable exception (TypeError) might lead to multiple loggers and therefore the wrong process id gets attached to logs CORE: [FIX] MicrosoftGraphEndpoint: Remove group member/owner ends in \"Write requests are only supported on contained entities\" CORE: [FIX] MicrosoftGraphEndpoint: Resolve all group members/owners (limit of 100 resources) CORE: [FIX] MicrosoftGraphEndpoint: Do not throw exception if /groups/{group}/team fails CORE: [CHANGE] Add attribute type #34","title":"1.0.0-beta39"},{"location":"server/changelog/#100-beta38","text":"Maintainer : Raffael Sahli Date : Tue Jul 16 14:28:23 CEST 2019 CORE: [FIX] GRAPH API (ODataRest) returns a 404 if an object was not found from id=x filter","title":"1.0.0-beta38"},{"location":"server/changelog/#100-beta37","text":"Maintainer : Raffael Sahli Date : Tue Jul 16 09:24:22 CEST 2019 CORE: [FIX] Member batch result verify team via status and not code CORE: [FIX] Validate Process/Job filter before register/update a new one CORE: [FIX] Validate Endpoint filter_all/filter_new before register/update a new one","title":"1.0.0-beta37"},{"location":"server/changelog/#100-beta36","text":"Maintainer : Raffael Sahli Date : Mon Jul 15 15:44:11 CEST 2019 CORE: [FIX] Fix DataObject relations to array conversion","title":"1.0.0-beta36"},{"location":"server/changelog/#100-beta35","text":"Maintainer : Raffael Sahli Date : Mon Jul 15 13:48:11 CEST 2019 CORE: [FIX] Fix order if resources were retrieved via api CORE: [CHANGE] Cache resolved relations during workflow executions","title":"1.0.0-beta35"},{"location":"server/changelog/#100-beta34","text":"Maintainer : Raffael Sahli Date : Mon Jul 15 10:45:14 CEST 2019 CORE: [FIX] Do not count objects during fetch if no limit was given","title":"1.0.0-beta34"},{"location":"server/changelog/#100-beta33","text":"Maintainer : Raffael Sahli Date : Mon Jul 15 10:44:11 CEST 2019 CORE: [FIX] Performance fix during fetching relations","title":"1.0.0-beta33"},{"location":"server/changelog/#100-beta32","text":"Maintainer : Raffael Sahli Date : Wed Jul 11 15:42:11 CEST 2019 CORE: [FIX] last_sync/last_successful_sync have an old timestamp #53","title":"1.0.0-beta32"},{"location":"server/changelog/#100-beta31","text":"Maintainer : Raffael Sahli Date : Tue Jul 09 09:04:11 CEST 2019 CORE: [FEATURE] Added MicrosoftGraph endpoint with support for groups and teams","title":"1.0.0-beta31"},{"location":"server/changelog/#100-beta30","text":"Maintainer : Raffael Sahli Date : Fri Jun 28 09:04:11 CEST 2019 CORE: [FIX] Import DataObject (update) does not update last_sync to current timestamp","title":"1.0.0-beta30"},{"location":"server/changelog/#100-beta29","text":"Maintainer : Raffael Sahli Date : Thu Jun 27 11:22:11 CEST 2019 CORE: [CHANGE] Includes exception for failed DataObject syncs CORE: [CHANGE] DataObject endpoint garbage is set to true if the DataObject does not exists on the endpoint","title":"1.0.0-beta29"},{"location":"server/changelog/#100-beta28","text":"Maintainer : Raffael Sahli Date : Tue Jun 18 13:45:12 CEST 2019 CORE: [FIX] Fixes stream","title":"1.0.0-beta28"},{"location":"server/changelog/#100-beta27","text":"Maintainer : Raffael Sahli Date : Tue Jun 18 11:03:12 CEST 2019 CORE: [FIX] Fixes watch changeStream","title":"1.0.0-beta27"},{"location":"server/changelog/#100-beta26","text":"Maintainer : Raffael Sahli Date : Mon Jun 17 16:57:12 CEST 2019 CORE: [FIX] DataObjectRealtion context gets now changed if the context changes during sync","title":"1.0.0-beta26"},{"location":"server/changelog/#100-beta25","text":"Maintainer : Raffael Sahli Date : Mon Jun 17 09:23:12 CEST 2019 CORE: [FIX] Added new logs mongodb index (parent, namespace) which drastically increase log request performance DOCS: [CHANGE] Added permalink extension (anchors) CORE: [FEATURE] Added predefined filters to workflow attributes CORE: [CHANGE] Update endpoint status of DataObject #49","title":"1.0.0-beta25"},{"location":"server/changelog/#100-beta24","text":"Maintainer : Raffael Sahli Date : Mon Jun 17 09:23:12 CEST 2019 CORE: [FIX] Do not sort if sort is equal {$natual: 1}, this is a default anyway but will slow down the query if mentioned","title":"1.0.0-beta24"},{"location":"server/changelog/#100-beta23","text":"Maintainer : Raffael Sahli Date : Wed Jun 12 14:01:12 CEST 2019 API: [FIX] error\":\"TypeError\",\"message\":\"Argument 3 passed to Tubee\\DataObjectRelation\\Factory::watch() must be of the type boolean, array given, called in /usr/share/tubee/src/lib/Rest/v1/ObjectRelations.php on line 80","title":"1.0.0-beta23"},{"location":"server/changelog/#100-beta22","text":"Maintainer : Raffael Sahli Date : Wed Jun 12 14:01:12 CEST 2019 API: [FIX] fixes process data Tubee\\Rest\\Middlewares\\ExceptionHandler,ERROR]: uncaught exception Unexpected property: data","title":"1.0.0-beta22"},{"location":"server/changelog/#100-beta21","text":"Maintainer : Raffael Sahli Date : Fri Jun 07 09:01:12 CEST 2019 CORE: [FIX] Add workflow with no data ends in Undefined index exception #44 API: [CHANGE] Added core.v1 prefix to all requests and resources in openapi/swagger schemas CORE: [CHANGE] Ucs endpoint must check search response for equality #45 API: [CHANGE] Added readonly flags to Job/Process/Endpoint,DataObjectRelation,DataObject status fieldss","title":"1.0.0-beta21"},{"location":"server/changelog/#100-beta20","text":"Maintainer : Raffael Sahli Date : Mon Jun 03 15:50:12 CEST 2019 CORE: [FIX] Using own log formatter for mongodb to encode most context as json since context may contain invalid mongodb field names ($ prefix or .)","title":"1.0.0-beta20"},{"location":"server/changelog/#100-beta19","text":"Maintainer : Raffael Sahli Date : Mon Jun 03 13:50:11 CEST 2019 CORE: [FIX] Always include $dn$ in Ucs change() CORE: [FIX] factories watch() include default filter like getAll()","title":"1.0.0-beta19"},{"location":"server/changelog/#100-beta18","text":"Maintainer : Raffael Sahli Date : Wed May 29 11:50:12 CEST 2019 CORE: [FIX] Skip objects if build() returns null","title":"1.0.0-beta18"},{"location":"server/changelog/#100-beta17","text":"Maintainer : Raffael Sahli Date : Tue May 28 16:49:12 CEST 2019 CORE: [FIX] Trying to get property 'relations' of non-object","title":"1.0.0-beta17"},{"location":"server/changelog/#100-beta16","text":"Maintainer : Raffael Sahli Date : Thu May 23 10:26:12 CEST 2019 CORE: [FIX] encode found export object, fixes MongoDB\\Driver\\Exception\\InvalidArgumentException: invalid document for insert: keys cannot begin with \"$\" CORE: [FIX] added missing simulate field to Job resource in swagger specs","title":"1.0.0-beta16"},{"location":"server/changelog/#100-beta15","text":"Maintainer : Raffael Sahli Date : Wed May 22 12:26:12 CEST 2019 CORE: [FIX] do not throw Exception\\ImportConditionNotMet if multiple data objects were found, sync relations first and log a warning instead CORE: [FIX] Wrong debug log: total counter is less than the current DataObject #40 CORE: [FIX] pdo endpoint (mssql) generates wrong filter #39 CORE: [FIX] Do not throw an exception during query for an non existing mssql field #38","title":"1.0.0-beta15"},{"location":"server/changelog/#100-beta14","text":"Maintainer : Raffael Sahli Date : Wed May 15 12:26:12 CEST 2019 CORE: [FIX] undefined class constant self::COLLECTION_NAME in Tubee\\DataObjectRelation\\Factory","title":"1.0.0-beta14"},{"location":"server/changelog/#100-beta13","text":"Maintainer : Raffael Sahli Date : Thu May 09 15:51:14 CEST 2019 CORE: [FIX] Error: Cannot access protected property Tubee\\DataObjectRelation\\Factory::$logger CORE: [FIX] Error: Cannot access protected property Tubee\\DataObjectRelation\\Factory::$resource_factory CORE: [FIX] MongoDB\\Driver\\Exception\\InvalidArgumentException: invalid document for insert: keys cannot contain \".\":","title":"1.0.0-beta13"},{"location":"server/changelog/#100-beta12","text":"Maintainer : Raffael Sahli Date : Wed May 08 17:06:12 CEST 2019 CORE: [FIX] TypeError: Argument 2 passed to Tubee\\Async\\Sync::export() must be of the type array, null given","title":"1.0.0-beta12"},{"location":"server/changelog/#100-beta11","text":"Maintainer : Raffael Sahli Date : Wed May 08 15:06:12 CEST 2019 CORE: [CHANGE] Set garbage endpoint flag to true if object gets removed from endpoint during export absent workflow CORE: [CHANGE] ldap entrydn from mapping gets normalized as well (all lowercase) CORE: [FIX] MongoDB\\Driver\\Exception\\BulkWriteException: WiredTigerIndex::insert: key too large to index, failing 1134 CORE: [CHANE] throw Tubee\\Workflow\\Exception\\ImportConditionNotMet if source data objects are not unique CORE: [FIX] sort operation does not work for sorting data object, endpoint, collection resources CORE: [FIX] Method StreamIterator\\StreamIterator::__toString() must not throw an exception, caught ErrorException: Undefined index: created in API: [CHANGE] If authentication failed a 401 gets returned instead of a 500 API: [CHANGE] filter is now a json encoded object in Process and Job resources CORE: [FIX] skip garbage collection if a filtered process was issued","title":"1.0.0-beta11"},{"location":"server/changelog/#100-beta10","text":"Maintainer : Raffael Sahli Date : Tue May 07 12:06:12 CEST 2019 CORE: [FIX] Undefined property: Tubee\\DataObjectRelation\\Factory::$logger in /usr/share/tubee/src/lib/DataObjectRelation/Factory.php:160 CORE: [FIX] nullable endpoint result after a seccond sync","title":"1.0.0-beta10"},{"location":"server/changelog/#100-beta9","text":"Maintainer : Raffael Sahli Date : Sun Apr 18 11:34:01 CEST 2019 CORE: [FIX] Ldap auth adapter dremscape dependency is no correctly recreated for every ldap auth adapter CORE: [FIX] Allow calls to /api and /api/v1 for everyone if authenticated","title":"1.0.0-beta9"},{"location":"server/changelog/#100-beta8","text":"Maintainer : Raffael Sahli Date : Sub Apr 14 15:04:01 CEST 2019 CORE: [FIX] automatically drop unresolvable relations and do not throw exception if such events occur during relation resolving CORE: [CHANGE] Add index for field name during collection creation CORE: [CHANGE] ensure index for import fields after updating endpoint CORE: [FIX] workflow priority ordner, 0 first CORE: [FIX] fixed getAll during ldap query if filter_all is null CORE: [FIX] fixed ldap endpoint non utf-8 data encoding CORE: [FIX] normalize ldap dn (ignore case of dn attribute parts)","title":"1.0.0-beta8"},{"location":"server/changelog/#100-beta7","text":"Maintainer : Raffael Sahli Date : Wed Apr 11 17:11:01 CEST 2019 CORE: [FIX] attributes of type array and unwind will now be properly converted to a list CORE: [FIX] fixed cancel process after setting job active to false","title":"1.0.0-beta7"},{"location":"server/changelog/#100-beta6","text":"Maintainer : Raffael Sahli Date : Wed Apr 11 15:51:01 CEST 2019 CORE: [CHANGE] attribute map type array converts to real numeric array CORE: [FIX] Undefined index: data in PATCH update job CORE: [CHANGE] creating dataobject relations on thy fly may now match multiple objects to create relations to","title":"1.0.0-beta6"},{"location":"server/changelog/#100-beta5","text":"Maintainer : Raffael Sahli Date : Wed Apr 11 10:51:01 CEST 2019 CORE: [CHANGE] log endpoint object during import/export workflows CORE: [FIX] ODataRest endpoint does not required specific declaration of the id CORE: [FIX] LdapEndpoint entrydn is now always lowercase CORE: [FIX] ignore ldap entrydn in diff CORE: [FEATURE] new option active for jobs. jobs may be enabled/disabled.","title":"1.0.0-beta5"},{"location":"server/changelog/#100-beta4","text":"Maintainer : Raffael Sahli Date : Fri Apr 05 16:51:01 CEST 2019 PACKAGING: [FIX] fixed TUBEE_CONFIG_DIR in docker image to /etc/tubee API: [FIX] Argument 5 passed to Tubee\\DataObject\\Factory::watch() must be of the type integer or null, boolean given API: [FIX] Argument 2 passed to Tubee\\DataObjectRelation\\Factory::watch() must implement interface MongoDB\\BSON\\ObjectIdInterface or be null, array given API: [FIX] Argument 6 passed to Tubee\\Resource\\Factory::watchFrom() must be of the type integer or null, object given, API: [FIX] Added default empty array to Workflow map.context CORE: [FIX] Invalid json (especially filter_one and filter_all) results now in Exception\\InvalidJson CORE: [FEATURE] Added new attribute map option writeonly to only apply attributes initially if true","title":"1.0.0-beta4"},{"location":"server/changelog/#100-beta3","text":"Maintainer : Raffael Sahli Date : Wed Apr 03 16:01:01 CEST 2019 API: [FIX] Added route /api to /api/v1 CORE: [FIX] Fixed route/acl middleware order CORE: [CHANGE] upgraded micro-auth to latest alpha which fixes Adapter\\Basic\\Ldap identifier issue CORE: [FIX] user password can now be changed correctly CORE: [CHANGE] Invalid secret key now responds with Tubee\\Secret\\Exception\\SecretNotResolvable instead Tubee\\Exception API: [CHANGE] Endpoints with default identifiers specify those now in the openapi specs","title":"1.0.0-beta3"},{"location":"server/changelog/#100-beta2","text":"Maintainer : Raffael Sahli Date : Mon Mar 25 15:14:01 CET 2019 TESTING: [CHANGE] Added new xml endpoint unit tests PACKAGING: [CHANGE] Dev docker container now sets TUBEE_SECRET_KEY PACKAGING: [FIX] fixes no make dep npm PACKAGING: [CHANGE] Dockerfile and Dockerfile-dev are no part of the server repo itself PACKAGING: [CHANGE] docker images now inherits from gyselroth/tubee:php7.2-fpm-v8js which already includes v8js DOCS: [CHANGE] Various fixes CORE: [FIX] Do not block GET /logs requests if log response from MongoDB is empty (do not use natural sorting) CORE: [FIX] Xml, Csv validators merge defaults before validation CORE: [FIX] fixed ldap filter concat for filter_all and custom query CORE: [CHANGE] StorageInterface::syncWriteStream() implementations do now fclose() the resource CORE: [FEATURE] Enhanced query transformation for xml endpoint, query to xpath including $and, $or, $gt, $gte, $lt, $lte, $ne CORE: [FIX] Fixes issue due xml object change with diff type AttributeMapInterface::ACTION_ADD CORE: [FIX] resource validation now takes place with mounted secrets CORE: [CHANGE] Replaced resource validators with Garden\\Schema\\Schema OpenAPI v3 validation CORE: [CHANGE] Added OpenAPI v3 specs besides swagger v2 CORE: [FEATURE] Added new resource type GarbageWorkflow which replaces the need to write a scripted condition and check for garbage run CORE: [FIX] Fixed workflow cleanup execution CORE: [FEATURE] Remove DataObjectRelation with GarbageWorkflows CORE: [CHANGE] CoreInstallation delta now initializes required MongoDB replset if this has not been done yet CORE: [CHANGE] Possibility to automatically remove DataObjectRelations during GarbageWorkflows (set map[].ensure to absent) CORE: [CHANGE] Refactoring Workflow into Workflow\\ImportWorkflow and Workflow\\ExportWorkflow CORE: [CHANGE] Added TUBEE_CACHE_ADAPTER and TUBEE_LOG_LEVEL env variables to default container config CORE: [CHANGE] All resource factories now depend on Resource\\Factory which itself uses a Psr cache for resource validation CORE: [FIX] flush: true results in \"TypeError: Argument 1 passed to Tubee\\DataObject\\Factory::deleteAll() must implement interface Tubee\\Collection\\CollectionInterface, boolean given\" CORE: [FEATURE] Added -f to cli jobs (flush queue) CORE: [FEATURE] Added (bool) skip to attribute mapping to skip attributes to map CORE: [CHANGE] endpoint filter_all and filter_one use the tubee (mongodb) dql now instead filters in endpoint specific formats CORE: [FEATURE] filter_one and filter_all can now be used for Csv and Json endpoints (Note that performance is not optimal since those formats do not have a propper query language and neither now indexing) CORE: [CHANGE] Added Endpoint\\LoggerTrait to apply generic endpoint operation logging CORE: [FIX] readOnly attributes get stripped out from request CORE: [FIX] binary values in Endpoint\\Ldap get base64 encoded CORE: [FEATURE] Possibility to set context data within map definition in worklow API: [FIX] uncaught exception: Argument 4 passed to Tubee\\Rest\\v1\\Processes::delete() must implement interface MongoDB\\BSON\\ObjectIdInterface API: [FIX] uncaught exception: Argument 1 passed to Tubee\\Secret\\Factory::getOne() must implement interface Tubee\\ResourceNamespace\\ResourceNamespaceInterface, string given at POST /api/v1/secrets API: [FIX] uncaught exception: Undefined variable: job] [object] (ErrorException(code: 0): Undefined variable: job at POST /api/v1/jobs API: [FIX] Added ImageEndpoint to openapi v3 specs API: [FIX] fixed max execution time of 5min for watch stream requests API: [FIX] Added reaOnly flags to openapi spec for readonly attributes (like created, changed, version) API: [FIX] Exception middleware catches now throwables instead just exceptions only","title":"1.0.0-beta2"},{"location":"server/changelog/#100-beta1","text":"Maintainer : Raffael Sahli Date : Fri Jan 25 17:14:01 CET 2019 Initial beta relase v1.0.0-beta1","title":"1.0.0-beta1"},{"location":"server/contribute/","text":"Contribute to tubee Did you find a bug or would you like to contribute a feature? You are certainly welcome to do so. Please always fill an issue first to discuss the matter. Do not start development without an open issue otherwise we do not know what you are working on. Bug If you just want to fill a bug report, please open your issue . We are encouraged to fix your bug to provide best software in the opensource community. Security flaw Do not open an issue for a possible security vulnerability, to protect yourself and others please contact to report your concern. Get the base git clone https://github.com/gyselroth/tubee.git Development The recomended way to get started in development is to use the available docker images. You need docker and docker-compose installed on your local machine. For starters you can use the full stack development composing configuration docker-compose-dev.yml . Start the development stack docker-compose -f docker-compose-dev.yml up and you are ready to go. The dev container will automatically install dependencies at startup and initialize the server. At the first time this may take a while. Note: You need the entire git base on your host to run the dev server since the base gets mounted in the dev container. Your tubee server is now available at https://localhost:8090 . Note: The dev server gets started with a self-signed ssl certificate. Make Always execute make via docker exec if your are developing with the tubee docker image. Update depenencies: docker exec INSTANCE make -C /srv/www/tubee deps (You do not need to install dependencies manually, the dev container automatically installs all depencies during start) See Building bellow for other make targets. Building Besides npm scripts like build and start you can use make to build this software. The following make targets are supported: build Build software, but do not package clean Clear build and dependencies deb Create debian packages deps Install dependencies dist Distribute (Create tar and deb packages) tar Create tar package test Execute testsuite phpcs Execute phpcs check phpstan Execute phpstan Docs Documentation is written in /docs and generated with mkdocs . Git commit Please make sure that you always specify the number of your issue starting with a hastag (#) within any git commits. Pull Request You are absolutely welcome to submit a pull request which references an open issue. Please make sure you're follwing coding standards and be sure all your modifications pass the build. Code of Conduct Please note that this project is released with a Contributor Code of Conduct . By participating in this project you agree to abide by its terms. License This software is freely available under the terms of GPL-3.0 , please respect this license and do not contribute software parts which are not compatible with GPL-3.0. Editor config This repository gets shipped with an .editorconfig configuration. For more information on how to configure your editor please visit editorconfig . Git pre commit hook Add the following lines to your git pre-commit hook file, otherwise your build will fail if you do not following code style: ./vendor/bin/php-cs-fixer fix --config=.php_cs.dist -v This automatically converts your code into the code style guidelines of this project otherwise your build will fail!","title":"Contribute to tubee"},{"location":"server/contribute/#contribute-to-tubee","text":"Did you find a bug or would you like to contribute a feature? You are certainly welcome to do so. Please always fill an issue first to discuss the matter. Do not start development without an open issue otherwise we do not know what you are working on.","title":"Contribute to tubee"},{"location":"server/contribute/#bug","text":"If you just want to fill a bug report, please open your issue . We are encouraged to fix your bug to provide best software in the opensource community.","title":"Bug"},{"location":"server/contribute/#security-flaw","text":"Do not open an issue for a possible security vulnerability, to protect yourself and others please contact to report your concern.","title":"Security flaw"},{"location":"server/contribute/#get-the-base","text":"git clone https://github.com/gyselroth/tubee.git","title":"Get the base"},{"location":"server/contribute/#development","text":"The recomended way to get started in development is to use the available docker images. You need docker and docker-compose installed on your local machine. For starters you can use the full stack development composing configuration docker-compose-dev.yml . Start the development stack docker-compose -f docker-compose-dev.yml up and you are ready to go. The dev container will automatically install dependencies at startup and initialize the server. At the first time this may take a while. Note: You need the entire git base on your host to run the dev server since the base gets mounted in the dev container. Your tubee server is now available at https://localhost:8090 . Note: The dev server gets started with a self-signed ssl certificate.","title":"Development"},{"location":"server/contribute/#make","text":"Always execute make via docker exec if your are developing with the tubee docker image. Update depenencies: docker exec INSTANCE make -C /srv/www/tubee deps (You do not need to install dependencies manually, the dev container automatically installs all depencies during start) See Building bellow for other make targets.","title":"Make"},{"location":"server/contribute/#building","text":"Besides npm scripts like build and start you can use make to build this software. The following make targets are supported: build Build software, but do not package clean Clear build and dependencies deb Create debian packages deps Install dependencies dist Distribute (Create tar and deb packages) tar Create tar package test Execute testsuite phpcs Execute phpcs check phpstan Execute phpstan","title":"Building"},{"location":"server/contribute/#docs","text":"Documentation is written in /docs and generated with mkdocs .","title":"Docs"},{"location":"server/contribute/#git-commit","text":"Please make sure that you always specify the number of your issue starting with a hastag (#) within any git commits.","title":"Git commit"},{"location":"server/contribute/#pull-request","text":"You are absolutely welcome to submit a pull request which references an open issue. Please make sure you're follwing coding standards and be sure all your modifications pass the build.","title":"Pull Request"},{"location":"server/contribute/#code-of-conduct","text":"Please note that this project is released with a Contributor Code of Conduct . By participating in this project you agree to abide by its terms.","title":"Code of Conduct"},{"location":"server/contribute/#license","text":"This software is freely available under the terms of GPL-3.0 , please respect this license and do not contribute software parts which are not compatible with GPL-3.0.","title":"License"},{"location":"server/contribute/#editor-config","text":"This repository gets shipped with an .editorconfig configuration. For more information on how to configure your editor please visit editorconfig .","title":"Editor config"},{"location":"server/contribute/#git-pre-commit-hook","text":"Add the following lines to your git pre-commit hook file, otherwise your build will fail if you do not following code style: ./vendor/bin/php-cs-fixer fix --config=.php_cs.dist -v This automatically converts your code into the code style guidelines of this project otherwise your build will fail!","title":"Git pre commit hook"},{"location":"server/installation-helm/","text":"","title":"Installation helm"},{"location":"server/installation/","text":"Deploy Server This is a step-by-step tutorial how to correctly deploy the tubee server. There are multiple supported ways to deploy tubee: Docker (docker-compose) Container orchestration plattform like Kubernetes ) helm Manually as tar archive Compile manually from source The docker deployment using docker-compose or a container orchestration platform like kubernetes is the recommended way to deploy tubee. And it is also the simplest way. Deploy tubee using debian packages, tar archives or even installing from source requires some advanced system knowledge. Docker (docker-compose) The easiest, fastest and recommended way to deploy a tubee environment is to spin it up using docker and docker-compose. Since the installation is not the same for different host os and docker can be started on Linux, Windows and Mac please visit the docker documentation on how to install docker and docker-compose . Requirements : * docker * docker-compose * curl mkdir tubee; cd tubee curl https://raw.githubusercontent.com/gyselroth/tubee/master/packaging/docker-compose/docker-compose.yaml docker-compose.yaml docker-compose up **Note** All tubee containers provide a version tag besides `latest`. It is best practice to use an exact version of a service instead the latest tag in production environment. The containers provide a `latest-unstable` tag for the tubee-jobs, tubee and tubee-web container. It is in no way reccomened to use pre-releases in production environments! If you want to install beta and alpha versions replace `latest` with `latest-unstable` or specify an exact version tag. Pre-releases are only ment for testing purposes and are in no way recommended in production environements! The default user is: br/ Username: admin br/ Password: admin br/ ## Using the tar archive Instead a deb package you may also use a tar archive and install tubee manually on your system. A tar archive is an already builded relase, you you just need to have all requirements installed on your system, you may have a look at [Manually install from source](#manually-install-from-source). ## Deploy on kubernetes (helm) See helm ## Manually install from source This topic is only for advanced users or developers and describes how to deploy tubee by installing from source. If you are a developer please also continue reading [this](https://github.com/gyselroth/tubee/blob/master/CONTRIBUTING.md) article. **Requirements**: * posix based operating system (Basically every linux/unix) * make * [comoser](https://getcomposer.org/download/) * git * php = 7.2 * php ext-mongodb * php ext-curl * php ext-mbstring * php ext-posix * php ext-pnctl * php ext-apcu * php ext-sysvmsg **Optional requirements**: * php ext-imagick (If you want to use The ImageEndpoint) * php ext-ldap (If you want to use LDAP authentication and/or the LdapEndpoint) * php ext-smb (If you want to use the SmbStorage) * php ext-xml (If you want to use the XmlEndpoint) * php ext-pdo (If you want to use the PdoEndpoint) * php ext-mysql (If you want ot use the MysqlEndpoint) This will only install the tubee server. Dependencies such as MongoDB do not get installed. You can install those dependencies either by using distributed packages, see [Debian based distribution](#debian-based-distribution) or by installing them seperately from source. ### Install tubee server ```sh git clone https://github.com/gyselroth/tubee.git cd tubee make install Note You can also create .deb or .tar packages using make. Just execute either make deb or make tar or make dist for both.","title":"Deploy Server"},{"location":"server/installation/#deploy-server","text":"This is a step-by-step tutorial how to correctly deploy the tubee server. There are multiple supported ways to deploy tubee: Docker (docker-compose) Container orchestration plattform like Kubernetes ) helm Manually as tar archive Compile manually from source The docker deployment using docker-compose or a container orchestration platform like kubernetes is the recommended way to deploy tubee. And it is also the simplest way. Deploy tubee using debian packages, tar archives or even installing from source requires some advanced system knowledge.","title":"Deploy Server"},{"location":"server/installation/#docker-docker-compose","text":"The easiest, fastest and recommended way to deploy a tubee environment is to spin it up using docker and docker-compose. Since the installation is not the same for different host os and docker can be started on Linux, Windows and Mac please visit the docker documentation on how to install docker and docker-compose . Requirements : * docker * docker-compose * curl mkdir tubee; cd tubee curl https://raw.githubusercontent.com/gyselroth/tubee/master/packaging/docker-compose/docker-compose.yaml docker-compose.yaml docker-compose up **Note** All tubee containers provide a version tag besides `latest`. It is best practice to use an exact version of a service instead the latest tag in production environment. The containers provide a `latest-unstable` tag for the tubee-jobs, tubee and tubee-web container. It is in no way reccomened to use pre-releases in production environments! If you want to install beta and alpha versions replace `latest` with `latest-unstable` or specify an exact version tag. Pre-releases are only ment for testing purposes and are in no way recommended in production environements! The default user is: br/ Username: admin br/ Password: admin br/ ## Using the tar archive Instead a deb package you may also use a tar archive and install tubee manually on your system. A tar archive is an already builded relase, you you just need to have all requirements installed on your system, you may have a look at [Manually install from source](#manually-install-from-source). ## Deploy on kubernetes (helm) See helm ## Manually install from source This topic is only for advanced users or developers and describes how to deploy tubee by installing from source. If you are a developer please also continue reading [this](https://github.com/gyselroth/tubee/blob/master/CONTRIBUTING.md) article. **Requirements**: * posix based operating system (Basically every linux/unix) * make * [comoser](https://getcomposer.org/download/) * git * php = 7.2 * php ext-mongodb * php ext-curl * php ext-mbstring * php ext-posix * php ext-pnctl * php ext-apcu * php ext-sysvmsg **Optional requirements**: * php ext-imagick (If you want to use The ImageEndpoint) * php ext-ldap (If you want to use LDAP authentication and/or the LdapEndpoint) * php ext-smb (If you want to use the SmbStorage) * php ext-xml (If you want to use the XmlEndpoint) * php ext-pdo (If you want to use the PdoEndpoint) * php ext-mysql (If you want ot use the MysqlEndpoint) This will only install the tubee server. Dependencies such as MongoDB do not get installed. You can install those dependencies either by using distributed packages, see [Debian based distribution](#debian-based-distribution) or by installing them seperately from source. ### Install tubee server ```sh git clone https://github.com/gyselroth/tubee.git cd tubee make install Note You can also create .deb or .tar packages using make. Just execute either make deb or make tar or make dist for both.","title":"Docker (docker-compose)"},{"location":"server/upgrade/","text":"v1.0.0-betax = v1.0.0-beta4 Upgrade is required: tubeecli upgrade -vvv","title":"Upgrade"},{"location":"server/upgrade/#v100-betax-v100-beta4","text":"Upgrade is required: tubeecli upgrade -vvv","title":"v1.0.0-betax =&gt; v1.0.0-beta4"},{"location":"tubectl/","text":"tubectl tubectl for Linux, Windows and OS X.","title":"tubectl"},{"location":"tubectl/#tubectl","text":"tubectl for Linux, Windows and OS X.","title":"tubectl"},{"location":"tubectl/changelog/","text":"1.0.0-beta17 Maintainer : Raffael Sahli Date : Tue Dec 03 17:02:02 CET 2019 Bugfixes create --from-template=xy does only work with core.v1 prefix Features Processes include estimated time of how long a process might take Processes include progress information 1.0.0-beta16 Maintainer : Raffael Sahli Date : Wed Sep 25 12:04:02 CEST 2019 CORE: [CHANGE] Handle StreamErrors during stream responses 1.0.0-beta15 Maintainer : Raffael Sahli Date : Thu Aug 16 10:59:03 CEST 2019 CORE: [CHANGE] Removed ramac borders, the list output is now a borderless table which is more compact CORE: [FIX] Fixed log exception output due a beta api change in the tubee api CORE: [CHANGE] Changed reverse sorting if using -t to use an indexed query instead $natural sorting. CORE: [FIX] TypeError: Cannot read property 'split' of undefined with get and no resource type #13 CORE: [FIX] Do not print out resources if the list is empty while multiple resource types are fetched CORE: [FIX] Error: Required parameter collection was null or undefined when calling getEndpoints #12 CORE: [FEATURE] Print process status during process following and exit after process is finished CORE: [FEATURE] Implement rollback command #14 1.0.0-beta14 Maintainer : Raffael Sahli Date : Tue Jul 09 11:28:03 CEST 2019 CORE: [FEATURE] Support for MicrosoftGraph endpoint 1.0.0-beta13 Maintainer : Raffael Sahli Date : Thu June 20 15:46:03 CEST 2019 PACKAGING: [CHANGE] Moved windows build from appveyor to travis 1.0.0-beta12 Maintainer : Raffael Sahli Date : Fri June 07 12:03:03 CEST 2019 CORE: [FIX] removed watch debug to stdout CORE: [FIX] multi resource alias dor instead re 1.0.0-beta11 Maintainer : Raffael Sahli Date : Fri June 07 12:03:03 CEST 2019 CORE: [CHANGE] apply can now handle List resources CORE: [FEATURE] Export and import multiple resources #7 1.0.0-beta10 Maintainer : Raffael Sahli Date : Thu May 23 09:39:03 CEST 2019 CORE: [FIX] sync --simulate works now correctly CORE: [FIX] apply new AccessRule now correcly adds the new resource without error 1.0.0-beta9 Maintainer : Raffael Sahli Date : Wed May 22 14:09:03 CEST 2019 CORE: [CHANGE] nexe downgrade due fs.readFileSync error (openapi.yml not found) 1.0.0-beta8 Maintainer : Raffael Sahli Date : Fri May 10 09:52:03 CEST 2019 CORE: [CHANGE] If --debug was applied and an exception occured during login operation the exception gets dumped to stdout CORE: [FEATURE] Added possibility to use = = in a query operation CORE: [FIX] sync operation with query 1.0.0-beta7 Maintainer : Raffael Sahli Date : Fri May 10 09:52:03 CEST 2019 CORE: [FIX] removed debug output if request ended in error (use --debug) CORE: [CHANGE] process time is now in a humanreadable format instead seconds CORE: [FIX] --tail/-t works now correctly CORE: [CHANGE] shortcut for --trace is now -T instead -t CORE: [CHANGE] --logs now includes the option -t (tail) CORE: [FEATURE] Added count/total resources after list and log output CORE: [FEATURE] Support for multiple context (use --context to specify a different one) CORE: [CHANGE] config can now be edited using tubectl edit config CORE: [FEATURE] Added --query/-q and --json-query to the sync command (Only sync specific objects) 1.0.0-beta6 Maintainer : Raffael Sahli Date : Fri Apr 05 16:51:01 CEST 2019 CORE: [CHANGE] removed users command alias CORE: [CHANGE] command alias for access-roles is now aro CORE: [CHANGE] command alias for access-rules is now aru CORE: [CHANGE] command alias for relations is now dor CORE: [FEATURE] added sync job command CORE: [CHANGE] The default of 100 objects was set down to 20 if --limit was not specified CORE: [CHANGE] if --trace is applied for the sync command, --follow is not required anymore CORE: [FIX] --trace for sync follow 1.0.0-beta5 Maintainer : Raffael Sahli Date : Wed Apr 03 16:02:01 CEST 2019 CORE: [FIX] secret resource alias is now correctly se instead duplicate of ar. CORE: [FIX] added missing command alias for edit access-rules CORE: [FIX] #TypeError: this.api.createAccessRule is not a function CORE: [FIX] fixed double name attribute if name has been specified in command line and -t has been used CORE: [FIX] login password prompt now hides password correctly and login works CORE: [FIX] log output gets ignored if --logs is specified without a propper resource name 1.0.0-beta4 Maintainer : Raffael Sahli Date : Wed Mar 27 09:13:14 CET 2019 PACKAGING: [FEATURE] Added chocolately package PACKAGING: [CHANGE] Automatically update homebrew formula after release CORE: [CHANGE] https:// may now be left out during login operation CORE: [FIX] --debug prints now requests during login operation CORE: [FIX] fixed Cannot read property 'DefaultApi' of undefined during login CORE: [FIX] Packaged with openapi v3 instead swagger v2 1.0.0-beta3 Maintainer : Raffael Sahli Date : Fri Mar 15 15:18:12 CET 2019 CORE: [CHANGE] explain now uses the OpenAPIv3 spec provided from tubee-sdk-node CORE: [CHANGE] explain includes oneOf and required CORE: [CHANGE] create --from-template also uses the OpenAPIv3 spec now CORE: [FIX] Missing workflow arguments (collection/endpoint) now display the help page instead \"(node:27089) UnhandledPromiseRejectionWarning: Error: Required parameter endpoint was null or undefined when calling getWorkflows.\" CORE: [FEATURE] added support for GarbageWorkflow resources CORE: [FIX] ignore empty resources in apply operation CORE: [CHANGE] better error handling for resource which are either invalid or have not been found CORE: [FEATURE] detect duplicate resources in apply operation (prints a warning and ignores duplicates) CORE: [CHANGE] --diff now compares to the last version by default. Optionally one can set a specific version. CORE: [CHANGE] shorthand command name for relations is now or (object relation) insteadof re CORE: [FIX] remove watch if set on endpoint-objects CORE: [CHANGE] exclude readOnly attributes from template processor CORE: [CHANGE] added readonly hint in explain if field is readOnly CORE: [FIX] Fixed --follow after exec a sync operation 1.0.0-beta2 Maintainer : Raffael Sahli Date : Thu Feb 07 16:59:12 CET 2019 beta release v1.0.0-beta2 1.0.0-beta1 Maintainer : Raffael Sahli Date : Fri Jan 25 17:18:12 CET 2019 Initial beta release v1.0.0-beta1","title":"Changelog"},{"location":"tubectl/changelog/#100-beta17","text":"Maintainer : Raffael Sahli Date : Tue Dec 03 17:02:02 CET 2019","title":"1.0.0-beta17"},{"location":"tubectl/changelog/#bugfixes","text":"create --from-template=xy does only work with core.v1 prefix","title":"Bugfixes"},{"location":"tubectl/changelog/#features","text":"Processes include estimated time of how long a process might take Processes include progress information","title":"Features"},{"location":"tubectl/changelog/#100-beta16","text":"Maintainer : Raffael Sahli Date : Wed Sep 25 12:04:02 CEST 2019 CORE: [CHANGE] Handle StreamErrors during stream responses","title":"1.0.0-beta16"},{"location":"tubectl/changelog/#100-beta15","text":"Maintainer : Raffael Sahli Date : Thu Aug 16 10:59:03 CEST 2019 CORE: [CHANGE] Removed ramac borders, the list output is now a borderless table which is more compact CORE: [FIX] Fixed log exception output due a beta api change in the tubee api CORE: [CHANGE] Changed reverse sorting if using -t to use an indexed query instead $natural sorting. CORE: [FIX] TypeError: Cannot read property 'split' of undefined with get and no resource type #13 CORE: [FIX] Do not print out resources if the list is empty while multiple resource types are fetched CORE: [FIX] Error: Required parameter collection was null or undefined when calling getEndpoints #12 CORE: [FEATURE] Print process status during process following and exit after process is finished CORE: [FEATURE] Implement rollback command #14","title":"1.0.0-beta15"},{"location":"tubectl/changelog/#100-beta14","text":"Maintainer : Raffael Sahli Date : Tue Jul 09 11:28:03 CEST 2019 CORE: [FEATURE] Support for MicrosoftGraph endpoint","title":"1.0.0-beta14"},{"location":"tubectl/changelog/#100-beta13","text":"Maintainer : Raffael Sahli Date : Thu June 20 15:46:03 CEST 2019 PACKAGING: [CHANGE] Moved windows build from appveyor to travis","title":"1.0.0-beta13"},{"location":"tubectl/changelog/#100-beta12","text":"Maintainer : Raffael Sahli Date : Fri June 07 12:03:03 CEST 2019 CORE: [FIX] removed watch debug to stdout CORE: [FIX] multi resource alias dor instead re","title":"1.0.0-beta12"},{"location":"tubectl/changelog/#100-beta11","text":"Maintainer : Raffael Sahli Date : Fri June 07 12:03:03 CEST 2019 CORE: [CHANGE] apply can now handle List resources CORE: [FEATURE] Export and import multiple resources #7","title":"1.0.0-beta11"},{"location":"tubectl/changelog/#100-beta10","text":"Maintainer : Raffael Sahli Date : Thu May 23 09:39:03 CEST 2019 CORE: [FIX] sync --simulate works now correctly CORE: [FIX] apply new AccessRule now correcly adds the new resource without error","title":"1.0.0-beta10"},{"location":"tubectl/changelog/#100-beta9","text":"Maintainer : Raffael Sahli Date : Wed May 22 14:09:03 CEST 2019 CORE: [CHANGE] nexe downgrade due fs.readFileSync error (openapi.yml not found)","title":"1.0.0-beta9"},{"location":"tubectl/changelog/#100-beta8","text":"Maintainer : Raffael Sahli Date : Fri May 10 09:52:03 CEST 2019 CORE: [CHANGE] If --debug was applied and an exception occured during login operation the exception gets dumped to stdout CORE: [FEATURE] Added possibility to use = = in a query operation CORE: [FIX] sync operation with query","title":"1.0.0-beta8"},{"location":"tubectl/changelog/#100-beta7","text":"Maintainer : Raffael Sahli Date : Fri May 10 09:52:03 CEST 2019 CORE: [FIX] removed debug output if request ended in error (use --debug) CORE: [CHANGE] process time is now in a humanreadable format instead seconds CORE: [FIX] --tail/-t works now correctly CORE: [CHANGE] shortcut for --trace is now -T instead -t CORE: [CHANGE] --logs now includes the option -t (tail) CORE: [FEATURE] Added count/total resources after list and log output CORE: [FEATURE] Support for multiple context (use --context to specify a different one) CORE: [CHANGE] config can now be edited using tubectl edit config CORE: [FEATURE] Added --query/-q and --json-query to the sync command (Only sync specific objects)","title":"1.0.0-beta7"},{"location":"tubectl/changelog/#100-beta6","text":"Maintainer : Raffael Sahli Date : Fri Apr 05 16:51:01 CEST 2019 CORE: [CHANGE] removed users command alias CORE: [CHANGE] command alias for access-roles is now aro CORE: [CHANGE] command alias for access-rules is now aru CORE: [CHANGE] command alias for relations is now dor CORE: [FEATURE] added sync job command CORE: [CHANGE] The default of 100 objects was set down to 20 if --limit was not specified CORE: [CHANGE] if --trace is applied for the sync command, --follow is not required anymore CORE: [FIX] --trace for sync follow","title":"1.0.0-beta6"},{"location":"tubectl/changelog/#100-beta5","text":"Maintainer : Raffael Sahli Date : Wed Apr 03 16:02:01 CEST 2019 CORE: [FIX] secret resource alias is now correctly se instead duplicate of ar. CORE: [FIX] added missing command alias for edit access-rules CORE: [FIX] #TypeError: this.api.createAccessRule is not a function CORE: [FIX] fixed double name attribute if name has been specified in command line and -t has been used CORE: [FIX] login password prompt now hides password correctly and login works CORE: [FIX] log output gets ignored if --logs is specified without a propper resource name","title":"1.0.0-beta5"},{"location":"tubectl/changelog/#100-beta4","text":"Maintainer : Raffael Sahli Date : Wed Mar 27 09:13:14 CET 2019 PACKAGING: [FEATURE] Added chocolately package PACKAGING: [CHANGE] Automatically update homebrew formula after release CORE: [CHANGE] https:// may now be left out during login operation CORE: [FIX] --debug prints now requests during login operation CORE: [FIX] fixed Cannot read property 'DefaultApi' of undefined during login CORE: [FIX] Packaged with openapi v3 instead swagger v2","title":"1.0.0-beta4"},{"location":"tubectl/changelog/#100-beta3","text":"Maintainer : Raffael Sahli Date : Fri Mar 15 15:18:12 CET 2019 CORE: [CHANGE] explain now uses the OpenAPIv3 spec provided from tubee-sdk-node CORE: [CHANGE] explain includes oneOf and required CORE: [CHANGE] create --from-template also uses the OpenAPIv3 spec now CORE: [FIX] Missing workflow arguments (collection/endpoint) now display the help page instead \"(node:27089) UnhandledPromiseRejectionWarning: Error: Required parameter endpoint was null or undefined when calling getWorkflows.\" CORE: [FEATURE] added support for GarbageWorkflow resources CORE: [FIX] ignore empty resources in apply operation CORE: [CHANGE] better error handling for resource which are either invalid or have not been found CORE: [FEATURE] detect duplicate resources in apply operation (prints a warning and ignores duplicates) CORE: [CHANGE] --diff now compares to the last version by default. Optionally one can set a specific version. CORE: [CHANGE] shorthand command name for relations is now or (object relation) insteadof re CORE: [FIX] remove watch if set on endpoint-objects CORE: [CHANGE] exclude readOnly attributes from template processor CORE: [CHANGE] added readonly hint in explain if field is readOnly CORE: [FIX] Fixed --follow after exec a sync operation","title":"1.0.0-beta3"},{"location":"tubectl/changelog/#100-beta2","text":"Maintainer : Raffael Sahli Date : Thu Feb 07 16:59:12 CET 2019 beta release v1.0.0-beta2","title":"1.0.0-beta2"},{"location":"tubectl/changelog/#100-beta1","text":"Maintainer : Raffael Sahli Date : Fri Jan 25 17:18:12 CET 2019 Initial beta release v1.0.0-beta1","title":"1.0.0-beta1"},{"location":"tubectl/contribute/","text":"Contribute to tubee-client-cli Did you find a bug or would you like to contribute a feature? You are certainly welcome to do so. Please always fill an issue first to discuss the matter. Do not start development without an open issue otherwise we do not know what you are working on. Bug If you just want to fill a bug report, please open your issue . We are encouraged to fix your bug to provide best software in the opensource community. Security flaw Do not open an issue for a possible security vulnerability, to protect yourself and others please contact to report your concern. Development Requirements: * nodejs (At least v8.0.0) including npm Get the base git clone https://github.com/gyselroth/tubee-client-cli.git Install dependencies build npm install npm build Git commit Please make sure that you always specify the number of your issue starting with a hastag (#) within any git commits. Pull Request You are absolutely welcome to submit a pull request which references an open issue. Please make sure you're follwing coding standards and be sure all your modifications pass the build. Code of Conduct Please note that this project is released with a Contributor Code of Conduct . By participating in this project you agree to abide by its terms. License This software is freely available under the terms of MIT , please respect this license and do not contribute software parts which are not compatible with MIT. Editor config This repository gets shipped with an .editorconfig configuration. For more information on how to configure your editor please visit editorconfig .","title":"Contribute to tubee-client-cli"},{"location":"tubectl/contribute/#contribute-to-tubee-client-cli","text":"Did you find a bug or would you like to contribute a feature? You are certainly welcome to do so. Please always fill an issue first to discuss the matter. Do not start development without an open issue otherwise we do not know what you are working on.","title":"Contribute to tubee-client-cli"},{"location":"tubectl/contribute/#bug","text":"If you just want to fill a bug report, please open your issue . We are encouraged to fix your bug to provide best software in the opensource community.","title":"Bug"},{"location":"tubectl/contribute/#security-flaw","text":"Do not open an issue for a possible security vulnerability, to protect yourself and others please contact to report your concern.","title":"Security flaw"},{"location":"tubectl/contribute/#development","text":"Requirements: * nodejs (At least v8.0.0) including npm","title":"Development"},{"location":"tubectl/contribute/#get-the-base","text":"git clone https://github.com/gyselroth/tubee-client-cli.git","title":"Get the base"},{"location":"tubectl/contribute/#install-dependencies-build","text":"npm install npm build","title":"Install dependencies &amp; build"},{"location":"tubectl/contribute/#git-commit","text":"Please make sure that you always specify the number of your issue starting with a hastag (#) within any git commits.","title":"Git commit"},{"location":"tubectl/contribute/#pull-request","text":"You are absolutely welcome to submit a pull request which references an open issue. Please make sure you're follwing coding standards and be sure all your modifications pass the build.","title":"Pull Request"},{"location":"tubectl/contribute/#code-of-conduct","text":"Please note that this project is released with a Contributor Code of Conduct . By participating in this project you agree to abide by its terms.","title":"Code of Conduct"},{"location":"tubectl/contribute/#license","text":"This software is freely available under the terms of MIT , please respect this license and do not contribute software parts which are not compatible with MIT.","title":"License"},{"location":"tubectl/contribute/#editor-config","text":"This repository gets shipped with an .editorconfig configuration. For more information on how to configure your editor please visit editorconfig .","title":"Editor config"},{"location":"tubectl/upgrade/","text":"","title":"Upgrade"}]}